{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa15f85c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:09.739591Z",
     "iopub.status.busy": "2022-08-11T16:38:09.738138Z",
     "iopub.status.idle": "2022-08-11T16:38:13.344985Z",
     "shell.execute_reply": "2022-08-11T16:38:13.343674Z"
    },
    "papermill": {
     "duration": 3.618572,
     "end_time": "2022-08-11T16:38:13.347924",
     "exception": false,
     "start_time": "2022-08-11T16:38:09.729352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib.pyplot import plot as plt\n",
    "import random\n",
    "import datetime\n",
    "import math\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from colorama import Fore, Back, Style\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ce81c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:13.359768Z",
     "iopub.status.busy": "2022-08-11T16:38:13.359124Z",
     "iopub.status.idle": "2022-08-11T16:38:13.369681Z",
     "shell.execute_reply": "2022-08-11T16:38:13.368694Z"
    },
    "papermill": {
     "duration": 0.018967,
     "end_time": "2022-08-11T16:38:13.372076",
     "exception": false,
     "start_time": "2022-08-11T16:38:13.353109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0140990",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:13.383665Z",
     "iopub.status.busy": "2022-08-11T16:38:13.383292Z",
     "iopub.status.idle": "2022-08-11T16:38:13.395480Z",
     "shell.execute_reply": "2022-08-11T16:38:13.394321Z"
    },
    "papermill": {
     "duration": 0.02091,
     "end_time": "2022-08-11T16:38:13.398041",
     "exception": false,
     "start_time": "2022-08-11T16:38:13.377131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584eeb39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:13.409844Z",
     "iopub.status.busy": "2022-08-11T16:38:13.409477Z",
     "iopub.status.idle": "2022-08-11T16:38:21.134229Z",
     "shell.execute_reply": "2022-08-11T16:38:21.133012Z"
    },
    "papermill": {
     "duration": 7.733612,
     "end_time": "2022-08-11T16:38:21.136923",
     "exception": false,
     "start_time": "2022-08-11T16:38:13.403311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_feather('../input/amexfeatureengineering/770_FE_train.feather')\n",
    "target = train.target\n",
    "FEATURES = [col for col in train.columns if col not in ['customer_ID','target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab27b7",
   "metadata": {
    "papermill": {
     "duration": 0.004748,
     "end_time": "2022-08-11T16:38:21.147065",
     "exception": false,
     "start_time": "2022-08-11T16:38:21.142317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The model\n",
    "\n",
    "Our model has four hidden layers, enriched by a skip connection and a Dropout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ca5939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:21.159188Z",
     "iopub.status.busy": "2022-08-11T16:38:21.157990Z",
     "iopub.status.idle": "2022-08-11T16:38:21.171560Z",
     "shell.execute_reply": "2022-08-11T16:38:21.170433Z"
    },
    "papermill": {
     "duration": 0.021954,
     "end_time": "2022-08-11T16:38:21.173904",
     "exception": false,
     "start_time": "2022-08-11T16:38:21.151950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "    def __init__(self, in_feat, hid_dim=512, activation=nn.ReLU(), dropout=0.5):\n",
    "        super(my_model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(in_feat)\n",
    "        self.encode = nn.utils.weight_norm(nn.Linear(in_feat, hid_dim))\n",
    "        self.activation = activation\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hid_dim)\n",
    "        self.hidden1 = nn.utils.weight_norm(nn.Linear(hid_dim, 256))\n",
    "        self.hidden2 = nn.utils.weight_norm(nn.Linear(256, 64))\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(64+hid_dim)\n",
    "        self.hidden3 = nn.utils.weight_norm(nn.Linear(64+hid_dim, 128))\n",
    "        self.hidden4 = nn.utils.weight_norm(nn.Linear(128, 128))\n",
    "        self.batch_norm4 = nn.BatchNorm1d(128)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.hidden5 = nn.utils.weight_norm(nn.Linear(128,16))\n",
    "        self.pred = nn.Linear(16, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = self.drop(self.activation(self.encode(self.batch_norm1(x))))\n",
    "        h1 = self.activation(self.hidden2(self.drop(self.activation(self.hidden1(self.batch_norm2(h0))))))\n",
    "        h = self.drop(torch.concat([h0, h1], dim=-1))\n",
    "        h = self.activation(self.hidden3(self.batch_norm3(h)))\n",
    "        h = self.activation(self.hidden4(h))\n",
    "        h = self.activation(self.hidden5(self.drop(self.batch_norm4(h))))\n",
    "        return self.pred(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca9f55a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:21.185573Z",
     "iopub.status.busy": "2022-08-11T16:38:21.185128Z",
     "iopub.status.idle": "2022-08-11T16:38:21.332962Z",
     "shell.execute_reply": "2022-08-11T16:38:21.331757Z"
    },
    "papermill": {
     "duration": 0.156913,
     "end_time": "2022-08-11T16:38:21.335994",
     "exception": false,
     "start_time": "2022-08-11T16:38:21.179081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for f,(t_idx,v_idx) in enumerate(skf.split(X=train,y=target)):\n",
    "    train.loc[v_idx,'kfold'] = int(f)\n",
    "\n",
    "train['kfold'] = train['kfold'].astype(int)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077499cf",
   "metadata": {
    "papermill": {
     "duration": 0.004829,
     "end_time": "2022-08-11T16:38:21.346529",
     "exception": false,
     "start_time": "2022-08-11T16:38:21.341700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "388a1098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:21.358453Z",
     "iopub.status.busy": "2022-08-11T16:38:21.358019Z",
     "iopub.status.idle": "2022-08-11T16:38:21.366778Z",
     "shell.execute_reply": "2022-08-11T16:38:21.365655Z"
    },
    "papermill": {
     "duration": 0.017536,
     "end_time": "2022-08-11T16:38:21.369184",
     "exception": false,
     "start_time": "2022-08-11T16:38:21.351648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AmexDataset:\n",
    "    def __init__(self,features,target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.target[idx] ,dtype=torch.float)          \n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63a06d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:21.381933Z",
     "iopub.status.busy": "2022-08-11T16:38:21.381570Z",
     "iopub.status.idle": "2022-08-11T16:38:21.391770Z",
     "shell.execute_reply": "2022-08-11T16:38:21.390598Z"
    },
    "papermill": {
     "duration": 0.019046,
     "end_time": "2022-08-11T16:38:21.394552",
     "exception": false,
     "start_time": "2022-08-11T16:38:21.375506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model,optimizer,scheduler,loss_fn,dataloader,device):\n",
    "    \n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for  data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs,target = data['x'].to(device),data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs[:,0],target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "def valid_fn(model,loss_fn,dataloader,device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = [] \n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs,target = data['x'].to(device),data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs[:,0],target.float())\n",
    "        final_loss +=loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0128bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:21.406046Z",
     "iopub.status.busy": "2022-08-11T16:38:21.405706Z",
     "iopub.status.idle": "2022-08-11T16:38:21.416515Z",
     "shell.execute_reply": "2022-08-11T16:38:21.415437Z"
    },
    "papermill": {
     "duration": 0.019208,
     "end_time": "2022-08-11T16:38:21.418780",
     "exception": false,
     "start_time": "2022-08-11T16:38:21.399572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FineTuneScheduler:\n",
    "    def __init__(self, epochs):\n",
    "        self.epochs = epochs\n",
    "        self.epochs_per_step = 0\n",
    "        self.frozen_layers = []\n",
    "\n",
    "    def copy_without_top(self, model, num_features):\n",
    "        self.frozen_layers = []\n",
    "\n",
    "        model_new = my_model(num_features)\n",
    "        model_new.load_state_dict(model.state_dict())\n",
    "\n",
    "        # Freeze all weights\n",
    "        for name, param in model_new.named_parameters():\n",
    "            layer_index = name.split('.')[0][-1]\n",
    "\n",
    "            if layer_index == 5:\n",
    "                continue\n",
    "\n",
    "            param.requires_grad = False\n",
    "\n",
    "            # Save frozen layer names\n",
    "            if layer_index not in self.frozen_layers:\n",
    "                self.frozen_layers.append(layer_index)\n",
    "\n",
    "        self.epochs_per_step = self.epochs // len(self.frozen_layers)\n",
    "\n",
    "        # Replace the top layers with another ones\n",
    "        model_new.batch_norm4 = nn.BatchNorm1d(128)\n",
    "        model_new.drop = nn.Dropout(0.5)\n",
    "        model_new.hidden5 = nn.utils.weight_norm(nn.Linear(128,16))\n",
    "        model_new.to(DEVICE)\n",
    "        return model_new\n",
    "\n",
    "    def step(self, epoch, model):\n",
    "        if len(self.frozen_layers) == 0:\n",
    "            return\n",
    "\n",
    "        if epoch % self.epochs_per_step == 0:\n",
    "            last_frozen_index = self.frozen_layers[-1]\n",
    "            \n",
    "            # Unfreeze parameters of the last frozen layer\n",
    "            for name, param in model.named_parameters():\n",
    "                layer_index = name.split('.')[0][-1]\n",
    "\n",
    "                if layer_index == last_frozen_index:\n",
    "                    param.requires_grad = True\n",
    "\n",
    "            del self.frozen_layers[-1]  # Remove the last layer as unfrozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbdcb7f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:21.431022Z",
     "iopub.status.busy": "2022-08-11T16:38:21.430077Z",
     "iopub.status.idle": "2022-08-11T16:38:21.436360Z",
     "shell.execute_reply": "2022-08-11T16:38:21.435293Z"
    },
    "papermill": {
     "duration": 0.014805,
     "end_time": "2022-08-11T16:38:21.438972",
     "exception": false,
     "start_time": "2022-08-11T16:38:21.424167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 1e-3\n",
    "NFOLDS = 5           #<-- Update\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab106781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:21.450810Z",
     "iopub.status.busy": "2022-08-11T16:38:21.450465Z",
     "iopub.status.idle": "2022-08-11T16:38:21.460514Z",
     "shell.execute_reply": "2022-08-11T16:38:21.459307Z"
    },
    "papermill": {
     "duration": 0.018836,
     "end_time": "2022-08-11T16:38:21.463126",
     "exception": false,
     "start_time": "2022-08-11T16:38:21.444290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "            \n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb09141d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:21.478880Z",
     "iopub.status.busy": "2022-08-11T16:38:21.478090Z",
     "iopub.status.idle": "2022-08-11T16:38:21.495305Z",
     "shell.execute_reply": "2022-08-11T16:38:21.494310Z"
    },
    "papermill": {
     "duration": 0.02952,
     "end_time": "2022-08-11T16:38:21.497660",
     "exception": false,
     "start_time": "2022-08-11T16:38:21.468140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold,seed):\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    def train_model(model,fine_tune_scheduler=None):\n",
    "    \n",
    "        x_train,y_train = train_df[FEATURES].values,train_df['target'].values\n",
    "        x_valid,y_valid = valid_df[FEATURES].values,valid_df['target'].values\n",
    "        \n",
    "      #  scaler = StandardScaler()\n",
    "        \n",
    "      #  x_train =  scaler.fit_transform(x_train)\n",
    "      #  x_valid = scaler.transform(x_valid)\n",
    "        \n",
    "        train_dataset = AmexDataset(x_train,y_train)\n",
    "        valid_dataset = AmexDataset(x_valid,y_valid)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[800, 1600, 2400, 3200, 4000, 4800, 5600, 6400, 7200], gamma=0.6)\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss_tr = SmoothBCEwLogits(smoothing=0.001)\n",
    "\n",
    "        oof = np.zeros((len(train),1))\n",
    "        best_loss = np.inf\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            if fine_tune_scheduler is not None:\n",
    "                fine_tune_scheduler.step(epoch, model)\n",
    "\n",
    "            train_loss = train_fn(model, optimizer, scheduler, loss_tr, trainloader, DEVICE)\n",
    "            valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "            print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss:.6f}, valid_loss: {valid_loss:.6f}\")\n",
    "\n",
    "            if np.isnan(valid_loss):\n",
    "                break\n",
    "            \n",
    "            if valid_loss < best_loss:\n",
    "                best_loss = valid_loss\n",
    "                oof[val_idx] = valid_preds\n",
    "                torch.save(model.state_dict(), f\"SEED{seed}_FOLD{fold}_.pth\")\n",
    "       \n",
    "        return oof\n",
    "\n",
    "    fine_tune_scheduler = FineTuneScheduler(EPOCHS)\n",
    "    \n",
    "    pretrained_model = my_model(len(FEATURES))\n",
    "    pretrained_model.to(DEVICE)\n",
    "    \n",
    "    print('1st Stage')\n",
    "    \n",
    "    # Train on scored + nonscored targets\n",
    "    train_model(pretrained_model)\n",
    "    \n",
    "    # Load the pretrained model with the best loss\n",
    "    pretrained_model = my_model(len(FEATURES))\n",
    "    pretrained_model.load_state_dict(torch.load(f\"SEED{seed}_FOLD{fold}_.pth\"))\n",
    "    pretrained_model.to(DEVICE)\n",
    "                                     \n",
    "    # Copy model without the top layer\n",
    "    final_model = fine_tune_scheduler.copy_without_top(pretrained_model,len(FEATURES))     \n",
    "    \n",
    "    print('2nd Stage / Fine Tuning....')\n",
    "                                     \n",
    "    oof = train_model(final_model,fine_tune_scheduler)       \n",
    "                                    \n",
    "    return oof                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "402ca848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:21.509725Z",
     "iopub.status.busy": "2022-08-11T16:38:21.509358Z",
     "iopub.status.idle": "2022-08-11T16:38:21.515391Z",
     "shell.execute_reply": "2022-08-11T16:38:21.514193Z"
    },
    "papermill": {
     "duration": 0.014821,
     "end_time": "2022-08-11T16:38:21.517804",
     "exception": false,
     "start_time": "2022-08-11T16:38:21.502983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), 1))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_ = run_training(fold, seed)\n",
    "        oof += oof_\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "390077e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T16:38:21.530093Z",
     "iopub.status.busy": "2022-08-11T16:38:21.529124Z",
     "iopub.status.idle": "2022-08-11T18:14:57.834960Z",
     "shell.execute_reply": "2022-08-11T18:14:57.831780Z"
    },
    "papermill": {
     "duration": 5796.315232,
     "end_time": "2022-08-11T18:14:57.838214",
     "exception": false,
     "start_time": "2022-08-11T16:38:21.522982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Stage\n",
      "SEED: 41, FOLD: 0, EPOCH: 0, train_loss: 0.245698, valid_loss: 0.224015\n",
      "SEED: 41, FOLD: 0, EPOCH: 1, train_loss: 0.229327, valid_loss: 0.223304\n",
      "SEED: 41, FOLD: 0, EPOCH: 2, train_loss: 0.225982, valid_loss: 0.222280\n",
      "SEED: 41, FOLD: 0, EPOCH: 3, train_loss: 0.224033, valid_loss: 0.220903\n",
      "SEED: 41, FOLD: 0, EPOCH: 4, train_loss: 0.222647, valid_loss: 0.220405\n",
      "SEED: 41, FOLD: 0, EPOCH: 5, train_loss: 0.220809, valid_loss: 0.220026\n",
      "SEED: 41, FOLD: 0, EPOCH: 6, train_loss: 0.219694, valid_loss: 0.219980\n",
      "SEED: 41, FOLD: 0, EPOCH: 7, train_loss: 0.218286, valid_loss: 0.219430\n",
      "SEED: 41, FOLD: 0, EPOCH: 8, train_loss: 0.216760, valid_loss: 0.219932\n",
      "SEED: 41, FOLD: 0, EPOCH: 9, train_loss: 0.215305, valid_loss: 0.219239\n",
      "SEED: 41, FOLD: 0, EPOCH: 10, train_loss: 0.214426, valid_loss: 0.219659\n",
      "SEED: 41, FOLD: 0, EPOCH: 11, train_loss: 0.213283, valid_loss: 0.220200\n",
      "SEED: 41, FOLD: 0, EPOCH: 12, train_loss: 0.212701, valid_loss: 0.220444\n",
      "SEED: 41, FOLD: 0, EPOCH: 13, train_loss: 0.212130, valid_loss: 0.220057\n",
      "SEED: 41, FOLD: 0, EPOCH: 14, train_loss: 0.211643, valid_loss: 0.219548\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 41, FOLD: 0, EPOCH: 0, train_loss: 0.230273, valid_loss: 0.220077\n",
      "SEED: 41, FOLD: 0, EPOCH: 1, train_loss: 0.214829, valid_loss: 0.220308\n",
      "SEED: 41, FOLD: 0, EPOCH: 2, train_loss: 0.214589, valid_loss: 0.219771\n",
      "SEED: 41, FOLD: 0, EPOCH: 3, train_loss: 0.214410, valid_loss: 0.219954\n",
      "SEED: 41, FOLD: 0, EPOCH: 4, train_loss: 0.214415, valid_loss: 0.220014\n",
      "SEED: 41, FOLD: 0, EPOCH: 5, train_loss: 0.214145, valid_loss: 0.219439\n",
      "SEED: 41, FOLD: 0, EPOCH: 6, train_loss: 0.214128, valid_loss: 0.220288\n",
      "SEED: 41, FOLD: 0, EPOCH: 7, train_loss: 0.214066, valid_loss: 0.219053\n",
      "SEED: 41, FOLD: 0, EPOCH: 8, train_loss: 0.213785, valid_loss: 0.220074\n",
      "SEED: 41, FOLD: 0, EPOCH: 9, train_loss: 0.213258, valid_loss: 0.219583\n",
      "SEED: 41, FOLD: 0, EPOCH: 10, train_loss: 0.213923, valid_loss: 0.219845\n",
      "SEED: 41, FOLD: 0, EPOCH: 11, train_loss: 0.213416, valid_loss: 0.219541\n",
      "SEED: 41, FOLD: 0, EPOCH: 12, train_loss: 0.212667, valid_loss: 0.220307\n",
      "SEED: 41, FOLD: 0, EPOCH: 13, train_loss: 0.212120, valid_loss: 0.220865\n",
      "SEED: 41, FOLD: 0, EPOCH: 14, train_loss: 0.211303, valid_loss: 0.220254\n",
      "1st Stage\n",
      "SEED: 41, FOLD: 1, EPOCH: 0, train_loss: 0.245233, valid_loss: 0.226627\n",
      "SEED: 41, FOLD: 1, EPOCH: 1, train_loss: 0.228983, valid_loss: 0.224667\n",
      "SEED: 41, FOLD: 1, EPOCH: 2, train_loss: 0.225804, valid_loss: 0.224964\n",
      "SEED: 41, FOLD: 1, EPOCH: 3, train_loss: 0.223535, valid_loss: 0.222670\n",
      "SEED: 41, FOLD: 1, EPOCH: 4, train_loss: 0.221991, valid_loss: 0.223015\n",
      "SEED: 41, FOLD: 1, EPOCH: 5, train_loss: 0.220372, valid_loss: 0.221444\n",
      "SEED: 41, FOLD: 1, EPOCH: 6, train_loss: 0.218985, valid_loss: 0.220763\n",
      "SEED: 41, FOLD: 1, EPOCH: 7, train_loss: 0.217357, valid_loss: 0.221033\n",
      "SEED: 41, FOLD: 1, EPOCH: 8, train_loss: 0.216323, valid_loss: 0.220813\n",
      "SEED: 41, FOLD: 1, EPOCH: 9, train_loss: 0.214336, valid_loss: 0.220358\n",
      "SEED: 41, FOLD: 1, EPOCH: 10, train_loss: 0.213575, valid_loss: 0.220814\n",
      "SEED: 41, FOLD: 1, EPOCH: 11, train_loss: 0.212826, valid_loss: 0.220993\n",
      "SEED: 41, FOLD: 1, EPOCH: 12, train_loss: 0.211616, valid_loss: 0.221233\n",
      "SEED: 41, FOLD: 1, EPOCH: 13, train_loss: 0.211404, valid_loss: 0.221560\n",
      "SEED: 41, FOLD: 1, EPOCH: 14, train_loss: 0.210768, valid_loss: 0.220971\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 41, FOLD: 1, EPOCH: 0, train_loss: 0.229050, valid_loss: 0.220889\n",
      "SEED: 41, FOLD: 1, EPOCH: 1, train_loss: 0.214021, valid_loss: 0.221110\n",
      "SEED: 41, FOLD: 1, EPOCH: 2, train_loss: 0.213514, valid_loss: 0.221783\n",
      "SEED: 41, FOLD: 1, EPOCH: 3, train_loss: 0.213189, valid_loss: 0.221397\n",
      "SEED: 41, FOLD: 1, EPOCH: 4, train_loss: 0.213491, valid_loss: 0.221234\n",
      "SEED: 41, FOLD: 1, EPOCH: 5, train_loss: 0.213340, valid_loss: 0.220475\n",
      "SEED: 41, FOLD: 1, EPOCH: 6, train_loss: 0.213314, valid_loss: 0.220978\n",
      "SEED: 41, FOLD: 1, EPOCH: 7, train_loss: 0.213386, valid_loss: 0.221144\n",
      "SEED: 41, FOLD: 1, EPOCH: 8, train_loss: 0.213087, valid_loss: 0.221534\n",
      "SEED: 41, FOLD: 1, EPOCH: 9, train_loss: 0.212674, valid_loss: 0.220712\n",
      "SEED: 41, FOLD: 1, EPOCH: 10, train_loss: 0.213570, valid_loss: 0.220958\n",
      "SEED: 41, FOLD: 1, EPOCH: 11, train_loss: 0.212244, valid_loss: 0.220917\n",
      "SEED: 41, FOLD: 1, EPOCH: 12, train_loss: 0.211715, valid_loss: 0.221367\n",
      "SEED: 41, FOLD: 1, EPOCH: 13, train_loss: 0.211123, valid_loss: 0.221990\n",
      "SEED: 41, FOLD: 1, EPOCH: 14, train_loss: 0.210513, valid_loss: 0.221159\n",
      "1st Stage\n",
      "SEED: 41, FOLD: 2, EPOCH: 0, train_loss: 0.246291, valid_loss: 0.223489\n",
      "SEED: 41, FOLD: 2, EPOCH: 1, train_loss: 0.229527, valid_loss: 0.222438\n",
      "SEED: 41, FOLD: 2, EPOCH: 2, train_loss: 0.226454, valid_loss: 0.221042\n",
      "SEED: 41, FOLD: 2, EPOCH: 3, train_loss: 0.224248, valid_loss: 0.220341\n",
      "SEED: 41, FOLD: 2, EPOCH: 4, train_loss: 0.222566, valid_loss: 0.219410\n",
      "SEED: 41, FOLD: 2, EPOCH: 5, train_loss: 0.221002, valid_loss: 0.218851\n",
      "SEED: 41, FOLD: 2, EPOCH: 6, train_loss: 0.219466, valid_loss: 0.218288\n",
      "SEED: 41, FOLD: 2, EPOCH: 7, train_loss: 0.217947, valid_loss: 0.218837\n",
      "SEED: 41, FOLD: 2, EPOCH: 8, train_loss: 0.216821, valid_loss: 0.218303\n",
      "SEED: 41, FOLD: 2, EPOCH: 9, train_loss: 0.215303, valid_loss: 0.218635\n",
      "SEED: 41, FOLD: 2, EPOCH: 10, train_loss: 0.214340, valid_loss: 0.218638\n",
      "SEED: 41, FOLD: 2, EPOCH: 11, train_loss: 0.213196, valid_loss: 0.219391\n",
      "SEED: 41, FOLD: 2, EPOCH: 12, train_loss: 0.212176, valid_loss: 0.219190\n",
      "SEED: 41, FOLD: 2, EPOCH: 13, train_loss: 0.211733, valid_loss: 0.219328\n",
      "SEED: 41, FOLD: 2, EPOCH: 14, train_loss: 0.211329, valid_loss: 0.219836\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 41, FOLD: 2, EPOCH: 0, train_loss: 0.232940, valid_loss: 0.218432\n",
      "SEED: 41, FOLD: 2, EPOCH: 1, train_loss: 0.218040, valid_loss: 0.219313\n",
      "SEED: 41, FOLD: 2, EPOCH: 2, train_loss: 0.217403, valid_loss: 0.218957\n",
      "SEED: 41, FOLD: 2, EPOCH: 3, train_loss: 0.217334, valid_loss: 0.218893\n",
      "SEED: 41, FOLD: 2, EPOCH: 4, train_loss: 0.217340, valid_loss: 0.218719\n",
      "SEED: 41, FOLD: 2, EPOCH: 5, train_loss: 0.217598, valid_loss: 0.218567\n",
      "SEED: 41, FOLD: 2, EPOCH: 6, train_loss: 0.217011, valid_loss: 0.219046\n",
      "SEED: 41, FOLD: 2, EPOCH: 7, train_loss: 0.217112, valid_loss: 0.218164\n",
      "SEED: 41, FOLD: 2, EPOCH: 8, train_loss: 0.217329, valid_loss: 0.218567\n",
      "SEED: 41, FOLD: 2, EPOCH: 9, train_loss: 0.216468, valid_loss: 0.218587\n",
      "SEED: 41, FOLD: 2, EPOCH: 10, train_loss: 0.217282, valid_loss: 0.219039\n",
      "SEED: 41, FOLD: 2, EPOCH: 11, train_loss: 0.215859, valid_loss: 0.218960\n",
      "SEED: 41, FOLD: 2, EPOCH: 12, train_loss: 0.215474, valid_loss: 0.218999\n",
      "SEED: 41, FOLD: 2, EPOCH: 13, train_loss: 0.214779, valid_loss: 0.219171\n",
      "SEED: 41, FOLD: 2, EPOCH: 14, train_loss: 0.214247, valid_loss: 0.218528\n",
      "1st Stage\n",
      "SEED: 41, FOLD: 3, EPOCH: 0, train_loss: 0.246300, valid_loss: 0.225052\n",
      "SEED: 41, FOLD: 3, EPOCH: 1, train_loss: 0.229171, valid_loss: 0.224846\n",
      "SEED: 41, FOLD: 3, EPOCH: 2, train_loss: 0.226105, valid_loss: 0.221535\n",
      "SEED: 41, FOLD: 3, EPOCH: 3, train_loss: 0.223978, valid_loss: 0.221074\n",
      "SEED: 41, FOLD: 3, EPOCH: 4, train_loss: 0.222204, valid_loss: 0.220158\n",
      "SEED: 41, FOLD: 3, EPOCH: 5, train_loss: 0.220063, valid_loss: 0.220480\n",
      "SEED: 41, FOLD: 3, EPOCH: 6, train_loss: 0.219065, valid_loss: 0.220236\n",
      "SEED: 41, FOLD: 3, EPOCH: 7, train_loss: 0.217211, valid_loss: 0.220395\n",
      "SEED: 41, FOLD: 3, EPOCH: 8, train_loss: 0.215944, valid_loss: 0.219807\n",
      "SEED: 41, FOLD: 3, EPOCH: 9, train_loss: 0.214453, valid_loss: 0.220243\n",
      "SEED: 41, FOLD: 3, EPOCH: 10, train_loss: 0.213463, valid_loss: 0.220935\n",
      "SEED: 41, FOLD: 3, EPOCH: 11, train_loss: 0.212557, valid_loss: 0.220132\n",
      "SEED: 41, FOLD: 3, EPOCH: 12, train_loss: 0.211988, valid_loss: 0.220341\n",
      "SEED: 41, FOLD: 3, EPOCH: 13, train_loss: 0.210796, valid_loss: 0.220795\n",
      "SEED: 41, FOLD: 3, EPOCH: 14, train_loss: 0.210414, valid_loss: 0.220640\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 41, FOLD: 3, EPOCH: 0, train_loss: 0.230190, valid_loss: 0.221249\n",
      "SEED: 41, FOLD: 3, EPOCH: 1, train_loss: 0.215043, valid_loss: 0.219966\n",
      "SEED: 41, FOLD: 3, EPOCH: 2, train_loss: 0.214845, valid_loss: 0.219466\n",
      "SEED: 41, FOLD: 3, EPOCH: 3, train_loss: 0.214609, valid_loss: 0.221077\n",
      "SEED: 41, FOLD: 3, EPOCH: 4, train_loss: 0.214936, valid_loss: 0.220435\n",
      "SEED: 41, FOLD: 3, EPOCH: 5, train_loss: 0.214476, valid_loss: 0.219834\n",
      "SEED: 41, FOLD: 3, EPOCH: 6, train_loss: 0.215045, valid_loss: 0.219430\n",
      "SEED: 41, FOLD: 3, EPOCH: 7, train_loss: 0.214679, valid_loss: 0.219575\n",
      "SEED: 41, FOLD: 3, EPOCH: 8, train_loss: 0.213997, valid_loss: 0.219357\n",
      "SEED: 41, FOLD: 3, EPOCH: 9, train_loss: 0.214244, valid_loss: 0.219754\n",
      "SEED: 41, FOLD: 3, EPOCH: 10, train_loss: 0.214335, valid_loss: 0.219946\n",
      "SEED: 41, FOLD: 3, EPOCH: 11, train_loss: 0.212826, valid_loss: 0.219984\n",
      "SEED: 41, FOLD: 3, EPOCH: 12, train_loss: 0.212586, valid_loss: 0.220464\n",
      "SEED: 41, FOLD: 3, EPOCH: 13, train_loss: 0.212287, valid_loss: 0.220619\n",
      "SEED: 41, FOLD: 3, EPOCH: 14, train_loss: 0.211393, valid_loss: 0.220420\n",
      "1st Stage\n",
      "SEED: 41, FOLD: 4, EPOCH: 0, train_loss: 0.246927, valid_loss: 0.224143\n",
      "SEED: 41, FOLD: 4, EPOCH: 1, train_loss: 0.230133, valid_loss: 0.221902\n",
      "SEED: 41, FOLD: 4, EPOCH: 2, train_loss: 0.226693, valid_loss: 0.219710\n",
      "SEED: 41, FOLD: 4, EPOCH: 3, train_loss: 0.224671, valid_loss: 0.219318\n",
      "SEED: 41, FOLD: 4, EPOCH: 4, train_loss: 0.222896, valid_loss: 0.218440\n",
      "SEED: 41, FOLD: 4, EPOCH: 5, train_loss: 0.220684, valid_loss: 0.218889\n",
      "SEED: 41, FOLD: 4, EPOCH: 6, train_loss: 0.219832, valid_loss: 0.218966\n",
      "SEED: 41, FOLD: 4, EPOCH: 7, train_loss: 0.218352, valid_loss: 0.218697\n",
      "SEED: 41, FOLD: 4, EPOCH: 8, train_loss: 0.217004, valid_loss: 0.217759\n",
      "SEED: 41, FOLD: 4, EPOCH: 9, train_loss: 0.215720, valid_loss: 0.218196\n",
      "SEED: 41, FOLD: 4, EPOCH: 10, train_loss: 0.214515, valid_loss: 0.219059\n",
      "SEED: 41, FOLD: 4, EPOCH: 11, train_loss: 0.213900, valid_loss: 0.218897\n",
      "SEED: 41, FOLD: 4, EPOCH: 12, train_loss: 0.212806, valid_loss: 0.218255\n",
      "SEED: 41, FOLD: 4, EPOCH: 13, train_loss: 0.212264, valid_loss: 0.218282\n",
      "SEED: 41, FOLD: 4, EPOCH: 14, train_loss: 0.211522, valid_loss: 0.218865\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 41, FOLD: 4, EPOCH: 0, train_loss: 0.230357, valid_loss: 0.218641\n",
      "SEED: 41, FOLD: 4, EPOCH: 1, train_loss: 0.216019, valid_loss: 0.218110\n",
      "SEED: 41, FOLD: 4, EPOCH: 2, train_loss: 0.215670, valid_loss: 0.218156\n",
      "SEED: 41, FOLD: 4, EPOCH: 3, train_loss: 0.215561, valid_loss: 0.218803\n",
      "SEED: 41, FOLD: 4, EPOCH: 4, train_loss: 0.215229, valid_loss: 0.218163\n",
      "SEED: 41, FOLD: 4, EPOCH: 5, train_loss: 0.215169, valid_loss: 0.217755\n",
      "SEED: 41, FOLD: 4, EPOCH: 6, train_loss: 0.215740, valid_loss: 0.217698\n",
      "SEED: 41, FOLD: 4, EPOCH: 7, train_loss: 0.215520, valid_loss: 0.218011\n",
      "SEED: 41, FOLD: 4, EPOCH: 8, train_loss: 0.214733, valid_loss: 0.217530\n",
      "SEED: 41, FOLD: 4, EPOCH: 9, train_loss: 0.214734, valid_loss: 0.218194\n",
      "SEED: 41, FOLD: 4, EPOCH: 10, train_loss: 0.215426, valid_loss: 0.218008\n",
      "SEED: 41, FOLD: 4, EPOCH: 11, train_loss: 0.214606, valid_loss: 0.217986\n",
      "SEED: 41, FOLD: 4, EPOCH: 12, train_loss: 0.213469, valid_loss: 0.218018\n",
      "SEED: 41, FOLD: 4, EPOCH: 13, train_loss: 0.213707, valid_loss: 0.219343\n",
      "SEED: 41, FOLD: 4, EPOCH: 14, train_loss: 0.212705, valid_loss: 0.218888\n",
      "1st Stage\n",
      "SEED: 42, FOLD: 0, EPOCH: 0, train_loss: 0.248277, valid_loss: 0.225286\n",
      "SEED: 42, FOLD: 0, EPOCH: 1, train_loss: 0.228790, valid_loss: 0.222734\n",
      "SEED: 42, FOLD: 0, EPOCH: 2, train_loss: 0.226133, valid_loss: 0.221654\n",
      "SEED: 42, FOLD: 0, EPOCH: 3, train_loss: 0.223772, valid_loss: 0.220808\n",
      "SEED: 42, FOLD: 0, EPOCH: 4, train_loss: 0.222097, valid_loss: 0.220022\n",
      "SEED: 42, FOLD: 0, EPOCH: 5, train_loss: 0.220073, valid_loss: 0.219795\n",
      "SEED: 42, FOLD: 0, EPOCH: 6, train_loss: 0.219195, valid_loss: 0.219205\n",
      "SEED: 42, FOLD: 0, EPOCH: 7, train_loss: 0.217437, valid_loss: 0.220540\n",
      "SEED: 42, FOLD: 0, EPOCH: 8, train_loss: 0.216361, valid_loss: 0.219323\n",
      "SEED: 42, FOLD: 0, EPOCH: 9, train_loss: 0.214767, valid_loss: 0.219043\n",
      "SEED: 42, FOLD: 0, EPOCH: 10, train_loss: 0.213816, valid_loss: 0.220186\n",
      "SEED: 42, FOLD: 0, EPOCH: 11, train_loss: 0.212975, valid_loss: 0.219881\n",
      "SEED: 42, FOLD: 0, EPOCH: 12, train_loss: 0.211757, valid_loss: 0.219847\n",
      "SEED: 42, FOLD: 0, EPOCH: 13, train_loss: 0.211512, valid_loss: 0.220120\n",
      "SEED: 42, FOLD: 0, EPOCH: 14, train_loss: 0.210755, valid_loss: 0.219894\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 42, FOLD: 0, EPOCH: 0, train_loss: 0.228135, valid_loss: 0.220151\n",
      "SEED: 42, FOLD: 0, EPOCH: 1, train_loss: 0.214441, valid_loss: 0.219323\n",
      "SEED: 42, FOLD: 0, EPOCH: 2, train_loss: 0.214107, valid_loss: 0.219838\n",
      "SEED: 42, FOLD: 0, EPOCH: 3, train_loss: 0.213815, valid_loss: 0.219034\n",
      "SEED: 42, FOLD: 0, EPOCH: 4, train_loss: 0.213762, valid_loss: 0.219820\n",
      "SEED: 42, FOLD: 0, EPOCH: 5, train_loss: 0.213701, valid_loss: 0.219518\n",
      "SEED: 42, FOLD: 0, EPOCH: 6, train_loss: 0.213769, valid_loss: 0.220044\n",
      "SEED: 42, FOLD: 0, EPOCH: 7, train_loss: 0.213361, valid_loss: 0.219817\n",
      "SEED: 42, FOLD: 0, EPOCH: 8, train_loss: 0.213664, valid_loss: 0.219058\n",
      "SEED: 42, FOLD: 0, EPOCH: 9, train_loss: 0.213454, valid_loss: 0.220013\n",
      "SEED: 42, FOLD: 0, EPOCH: 10, train_loss: 0.213885, valid_loss: 0.219485\n",
      "SEED: 42, FOLD: 0, EPOCH: 11, train_loss: 0.212687, valid_loss: 0.219156\n",
      "SEED: 42, FOLD: 0, EPOCH: 12, train_loss: 0.211833, valid_loss: 0.219789\n",
      "SEED: 42, FOLD: 0, EPOCH: 13, train_loss: 0.211441, valid_loss: 0.220086\n",
      "SEED: 42, FOLD: 0, EPOCH: 14, train_loss: 0.211198, valid_loss: 0.220334\n",
      "1st Stage\n",
      "SEED: 42, FOLD: 1, EPOCH: 0, train_loss: 0.247785, valid_loss: 0.227071\n",
      "SEED: 42, FOLD: 1, EPOCH: 1, train_loss: 0.228642, valid_loss: 0.224390\n",
      "SEED: 42, FOLD: 1, EPOCH: 2, train_loss: 0.225846, valid_loss: 0.223823\n",
      "SEED: 42, FOLD: 1, EPOCH: 3, train_loss: 0.223790, valid_loss: 0.223239\n",
      "SEED: 42, FOLD: 1, EPOCH: 4, train_loss: 0.221812, valid_loss: 0.222040\n",
      "SEED: 42, FOLD: 1, EPOCH: 5, train_loss: 0.220048, valid_loss: 0.221341\n",
      "SEED: 42, FOLD: 1, EPOCH: 6, train_loss: 0.219135, valid_loss: 0.220299\n",
      "SEED: 42, FOLD: 1, EPOCH: 7, train_loss: 0.217257, valid_loss: 0.221320\n",
      "SEED: 42, FOLD: 1, EPOCH: 8, train_loss: 0.216357, valid_loss: 0.220359\n",
      "SEED: 42, FOLD: 1, EPOCH: 9, train_loss: 0.214839, valid_loss: 0.220436\n",
      "SEED: 42, FOLD: 1, EPOCH: 10, train_loss: 0.213294, valid_loss: 0.220601\n",
      "SEED: 42, FOLD: 1, EPOCH: 11, train_loss: 0.212596, valid_loss: 0.221114\n",
      "SEED: 42, FOLD: 1, EPOCH: 12, train_loss: 0.211597, valid_loss: 0.221102\n",
      "SEED: 42, FOLD: 1, EPOCH: 13, train_loss: 0.211302, valid_loss: 0.221437\n",
      "SEED: 42, FOLD: 1, EPOCH: 14, train_loss: 0.210440, valid_loss: 0.220701\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 42, FOLD: 1, EPOCH: 0, train_loss: 0.232706, valid_loss: 0.220903\n",
      "SEED: 42, FOLD: 1, EPOCH: 1, train_loss: 0.217427, valid_loss: 0.220633\n",
      "SEED: 42, FOLD: 1, EPOCH: 2, train_loss: 0.217248, valid_loss: 0.220554\n",
      "SEED: 42, FOLD: 1, EPOCH: 3, train_loss: 0.216987, valid_loss: 0.220552\n",
      "SEED: 42, FOLD: 1, EPOCH: 4, train_loss: 0.217044, valid_loss: 0.220813\n",
      "SEED: 42, FOLD: 1, EPOCH: 5, train_loss: 0.216789, valid_loss: 0.220858\n",
      "SEED: 42, FOLD: 1, EPOCH: 6, train_loss: 0.216971, valid_loss: 0.220735\n",
      "SEED: 42, FOLD: 1, EPOCH: 7, train_loss: 0.216605, valid_loss: 0.220492\n",
      "SEED: 42, FOLD: 1, EPOCH: 8, train_loss: 0.216560, valid_loss: 0.219993\n",
      "SEED: 42, FOLD: 1, EPOCH: 9, train_loss: 0.216296, valid_loss: 0.220374\n",
      "SEED: 42, FOLD: 1, EPOCH: 10, train_loss: 0.216516, valid_loss: 0.220359\n",
      "SEED: 42, FOLD: 1, EPOCH: 11, train_loss: 0.215430, valid_loss: 0.220127\n",
      "SEED: 42, FOLD: 1, EPOCH: 12, train_loss: 0.214836, valid_loss: 0.220409\n",
      "SEED: 42, FOLD: 1, EPOCH: 13, train_loss: 0.214043, valid_loss: 0.220568\n",
      "SEED: 42, FOLD: 1, EPOCH: 14, train_loss: 0.214012, valid_loss: 0.220578\n",
      "1st Stage\n",
      "SEED: 42, FOLD: 2, EPOCH: 0, train_loss: 0.248353, valid_loss: 0.224033\n",
      "SEED: 42, FOLD: 2, EPOCH: 1, train_loss: 0.229517, valid_loss: 0.221543\n",
      "SEED: 42, FOLD: 2, EPOCH: 2, train_loss: 0.226132, valid_loss: 0.220734\n",
      "SEED: 42, FOLD: 2, EPOCH: 3, train_loss: 0.224247, valid_loss: 0.221651\n",
      "SEED: 42, FOLD: 2, EPOCH: 4, train_loss: 0.222633, valid_loss: 0.219378\n",
      "SEED: 42, FOLD: 2, EPOCH: 5, train_loss: 0.220665, valid_loss: 0.219076\n",
      "SEED: 42, FOLD: 2, EPOCH: 6, train_loss: 0.219684, valid_loss: 0.218956\n",
      "SEED: 42, FOLD: 2, EPOCH: 7, train_loss: 0.218207, valid_loss: 0.219075\n",
      "SEED: 42, FOLD: 2, EPOCH: 8, train_loss: 0.216793, valid_loss: 0.218890\n",
      "SEED: 42, FOLD: 2, EPOCH: 9, train_loss: 0.215153, valid_loss: 0.219005\n",
      "SEED: 42, FOLD: 2, EPOCH: 10, train_loss: 0.213994, valid_loss: 0.219429\n",
      "SEED: 42, FOLD: 2, EPOCH: 11, train_loss: 0.213240, valid_loss: 0.219091\n",
      "SEED: 42, FOLD: 2, EPOCH: 12, train_loss: 0.212758, valid_loss: 0.219745\n",
      "SEED: 42, FOLD: 2, EPOCH: 13, train_loss: 0.212011, valid_loss: 0.219238\n",
      "SEED: 42, FOLD: 2, EPOCH: 14, train_loss: 0.211349, valid_loss: 0.219216\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 42, FOLD: 2, EPOCH: 0, train_loss: 0.230100, valid_loss: 0.219332\n",
      "SEED: 42, FOLD: 2, EPOCH: 1, train_loss: 0.215494, valid_loss: 0.219903\n",
      "SEED: 42, FOLD: 2, EPOCH: 2, train_loss: 0.215340, valid_loss: 0.219286\n",
      "SEED: 42, FOLD: 2, EPOCH: 3, train_loss: 0.215024, valid_loss: 0.219395\n",
      "SEED: 42, FOLD: 2, EPOCH: 4, train_loss: 0.214996, valid_loss: 0.221042\n",
      "SEED: 42, FOLD: 2, EPOCH: 5, train_loss: 0.214667, valid_loss: 0.219008\n",
      "SEED: 42, FOLD: 2, EPOCH: 6, train_loss: 0.214719, valid_loss: 0.219141\n",
      "SEED: 42, FOLD: 2, EPOCH: 7, train_loss: 0.214625, valid_loss: 0.218952\n",
      "SEED: 42, FOLD: 2, EPOCH: 8, train_loss: 0.214788, valid_loss: 0.219232\n",
      "SEED: 42, FOLD: 2, EPOCH: 9, train_loss: 0.214513, valid_loss: 0.218795\n",
      "SEED: 42, FOLD: 2, EPOCH: 10, train_loss: 0.214664, valid_loss: 0.219209\n",
      "SEED: 42, FOLD: 2, EPOCH: 11, train_loss: 0.214172, valid_loss: 0.218434\n",
      "SEED: 42, FOLD: 2, EPOCH: 12, train_loss: 0.213499, valid_loss: 0.219039\n",
      "SEED: 42, FOLD: 2, EPOCH: 13, train_loss: 0.212413, valid_loss: 0.219085\n",
      "SEED: 42, FOLD: 2, EPOCH: 14, train_loss: 0.212497, valid_loss: 0.219671\n",
      "1st Stage\n",
      "SEED: 42, FOLD: 3, EPOCH: 0, train_loss: 0.247994, valid_loss: 0.224826\n",
      "SEED: 42, FOLD: 3, EPOCH: 1, train_loss: 0.228868, valid_loss: 0.223260\n",
      "SEED: 42, FOLD: 3, EPOCH: 2, train_loss: 0.225631, valid_loss: 0.221756\n",
      "SEED: 42, FOLD: 3, EPOCH: 3, train_loss: 0.223954, valid_loss: 0.220480\n",
      "SEED: 42, FOLD: 3, EPOCH: 4, train_loss: 0.222201, valid_loss: 0.220175\n",
      "SEED: 42, FOLD: 3, EPOCH: 5, train_loss: 0.220383, valid_loss: 0.220137\n",
      "SEED: 42, FOLD: 3, EPOCH: 6, train_loss: 0.219234, valid_loss: 0.220547\n",
      "SEED: 42, FOLD: 3, EPOCH: 7, train_loss: 0.217306, valid_loss: 0.219917\n",
      "SEED: 42, FOLD: 3, EPOCH: 8, train_loss: 0.216055, valid_loss: 0.220068\n",
      "SEED: 42, FOLD: 3, EPOCH: 9, train_loss: 0.214666, valid_loss: 0.220360\n",
      "SEED: 42, FOLD: 3, EPOCH: 10, train_loss: 0.213513, valid_loss: 0.221148\n",
      "SEED: 42, FOLD: 3, EPOCH: 11, train_loss: 0.212682, valid_loss: 0.220580\n",
      "SEED: 42, FOLD: 3, EPOCH: 12, train_loss: 0.211914, valid_loss: 0.220725\n",
      "SEED: 42, FOLD: 3, EPOCH: 13, train_loss: 0.211126, valid_loss: 0.220324\n",
      "SEED: 42, FOLD: 3, EPOCH: 14, train_loss: 0.210336, valid_loss: 0.220986\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 42, FOLD: 3, EPOCH: 0, train_loss: 0.230608, valid_loss: 0.220251\n",
      "SEED: 42, FOLD: 3, EPOCH: 1, train_loss: 0.215786, valid_loss: 0.221460\n",
      "SEED: 42, FOLD: 3, EPOCH: 2, train_loss: 0.216025, valid_loss: 0.220208\n",
      "SEED: 42, FOLD: 3, EPOCH: 3, train_loss: 0.215692, valid_loss: 0.220161\n",
      "SEED: 42, FOLD: 3, EPOCH: 4, train_loss: 0.215721, valid_loss: 0.219811\n",
      "SEED: 42, FOLD: 3, EPOCH: 5, train_loss: 0.215281, valid_loss: 0.219762\n",
      "SEED: 42, FOLD: 3, EPOCH: 6, train_loss: 0.215586, valid_loss: 0.219828\n",
      "SEED: 42, FOLD: 3, EPOCH: 7, train_loss: 0.215533, valid_loss: 0.219562\n",
      "SEED: 42, FOLD: 3, EPOCH: 8, train_loss: 0.215275, valid_loss: 0.220820\n",
      "SEED: 42, FOLD: 3, EPOCH: 9, train_loss: 0.214780, valid_loss: 0.220087\n",
      "SEED: 42, FOLD: 3, EPOCH: 10, train_loss: 0.215165, valid_loss: 0.219835\n",
      "SEED: 42, FOLD: 3, EPOCH: 11, train_loss: 0.214426, valid_loss: 0.220087\n",
      "SEED: 42, FOLD: 3, EPOCH: 12, train_loss: 0.213634, valid_loss: 0.219872\n",
      "SEED: 42, FOLD: 3, EPOCH: 13, train_loss: 0.213096, valid_loss: 0.220141\n",
      "SEED: 42, FOLD: 3, EPOCH: 14, train_loss: 0.212551, valid_loss: 0.220397\n",
      "1st Stage\n",
      "SEED: 42, FOLD: 4, EPOCH: 0, train_loss: 0.247892, valid_loss: 0.223531\n",
      "SEED: 42, FOLD: 4, EPOCH: 1, train_loss: 0.229325, valid_loss: 0.221127\n",
      "SEED: 42, FOLD: 4, EPOCH: 2, train_loss: 0.226425, valid_loss: 0.219868\n",
      "SEED: 42, FOLD: 4, EPOCH: 3, train_loss: 0.224621, valid_loss: 0.218582\n",
      "SEED: 42, FOLD: 4, EPOCH: 4, train_loss: 0.222892, valid_loss: 0.218613\n",
      "SEED: 42, FOLD: 4, EPOCH: 5, train_loss: 0.220974, valid_loss: 0.218302\n",
      "SEED: 42, FOLD: 4, EPOCH: 6, train_loss: 0.220128, valid_loss: 0.217978\n",
      "SEED: 42, FOLD: 4, EPOCH: 7, train_loss: 0.217792, valid_loss: 0.217961\n",
      "SEED: 42, FOLD: 4, EPOCH: 8, train_loss: 0.216495, valid_loss: 0.218033\n",
      "SEED: 42, FOLD: 4, EPOCH: 9, train_loss: 0.215528, valid_loss: 0.218354\n",
      "SEED: 42, FOLD: 4, EPOCH: 10, train_loss: 0.214368, valid_loss: 0.218609\n",
      "SEED: 42, FOLD: 4, EPOCH: 11, train_loss: 0.213847, valid_loss: 0.218257\n",
      "SEED: 42, FOLD: 4, EPOCH: 12, train_loss: 0.212781, valid_loss: 0.217784\n",
      "SEED: 42, FOLD: 4, EPOCH: 13, train_loss: 0.212037, valid_loss: 0.217471\n",
      "SEED: 42, FOLD: 4, EPOCH: 14, train_loss: 0.211680, valid_loss: 0.218588\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 42, FOLD: 4, EPOCH: 0, train_loss: 0.225754, valid_loss: 0.218050\n",
      "SEED: 42, FOLD: 4, EPOCH: 1, train_loss: 0.211997, valid_loss: 0.218971\n",
      "SEED: 42, FOLD: 4, EPOCH: 2, train_loss: 0.211556, valid_loss: 0.218282\n",
      "SEED: 42, FOLD: 4, EPOCH: 3, train_loss: 0.211740, valid_loss: 0.218498\n",
      "SEED: 42, FOLD: 4, EPOCH: 4, train_loss: 0.211507, valid_loss: 0.217855\n",
      "SEED: 42, FOLD: 4, EPOCH: 5, train_loss: 0.211505, valid_loss: 0.217973\n",
      "SEED: 42, FOLD: 4, EPOCH: 6, train_loss: 0.211671, valid_loss: 0.218685\n",
      "SEED: 42, FOLD: 4, EPOCH: 7, train_loss: 0.211779, valid_loss: 0.218458\n",
      "SEED: 42, FOLD: 4, EPOCH: 8, train_loss: 0.211284, valid_loss: 0.218320\n",
      "SEED: 42, FOLD: 4, EPOCH: 9, train_loss: 0.211149, valid_loss: 0.218367\n",
      "SEED: 42, FOLD: 4, EPOCH: 10, train_loss: 0.212001, valid_loss: 0.218784\n",
      "SEED: 42, FOLD: 4, EPOCH: 11, train_loss: 0.210761, valid_loss: 0.218692\n",
      "SEED: 42, FOLD: 4, EPOCH: 12, train_loss: 0.210429, valid_loss: 0.218373\n",
      "SEED: 42, FOLD: 4, EPOCH: 13, train_loss: 0.209720, valid_loss: 0.218482\n",
      "SEED: 42, FOLD: 4, EPOCH: 14, train_loss: 0.209154, valid_loss: 0.219125\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [41,42]  #<-- Update\n",
    "oof = np.zeros((len(train),1))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c7c75a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T18:14:57.886854Z",
     "iopub.status.busy": "2022-08-11T18:14:57.886415Z",
     "iopub.status.idle": "2022-08-11T18:14:58.099641Z",
     "shell.execute_reply": "2022-08-11T18:14:58.098356Z"
    },
    "papermill": {
     "duration": 0.240375,
     "end_time": "2022-08-11T18:14:58.102660",
     "exception": false,
     "start_time": "2022-08-11T18:14:57.862285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_ap = amex_metric_mod(target,oof[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d793e67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T18:14:58.151066Z",
     "iopub.status.busy": "2022-08-11T18:14:58.150608Z",
     "iopub.status.idle": "2022-08-11T18:14:58.160697Z",
     "shell.execute_reply": "2022-08-11T18:14:58.159666Z"
    },
    "papermill": {
     "duration": 0.036858,
     "end_time": "2022-08-11T18:14:58.163075",
     "exception": false,
     "start_time": "2022-08-11T18:14:58.126217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7915815533640204"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d1ca8a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T18:14:58.212695Z",
     "iopub.status.busy": "2022-08-11T18:14:58.212216Z",
     "iopub.status.idle": "2022-08-11T18:14:59.526318Z",
     "shell.execute_reply": "2022-08-11T18:14:59.524958Z"
    },
    "papermill": {
     "duration": 1.341713,
     "end_time": "2022-08-11T18:14:59.529218",
     "exception": false,
     "start_time": "2022-08-11T18:14:58.187505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof = pd.DataFrame({'customer_ID':train.customer_ID,'target':train.target,'oof_pred':oof[:,0]})\n",
    "oof.to_csv('oof_transfer_learning.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5823.05838,
   "end_time": "2022-08-11T18:15:01.992518",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-11T16:37:58.934138",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
