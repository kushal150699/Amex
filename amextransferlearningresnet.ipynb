{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1975f78c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:40.114295Z",
     "iopub.status.busy": "2022-08-11T17:18:40.113733Z",
     "iopub.status.idle": "2022-08-11T17:18:43.052660Z",
     "shell.execute_reply": "2022-08-11T17:18:43.051719Z"
    },
    "papermill": {
     "duration": 2.948953,
     "end_time": "2022-08-11T17:18:43.055577",
     "exception": false,
     "start_time": "2022-08-11T17:18:40.106624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib.pyplot import plot as plt\n",
    "import random\n",
    "import datetime\n",
    "import math\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from colorama import Fore, Back, Style\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc8b9e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:43.067813Z",
     "iopub.status.busy": "2022-08-11T17:18:43.067295Z",
     "iopub.status.idle": "2022-08-11T17:18:43.076263Z",
     "shell.execute_reply": "2022-08-11T17:18:43.075429Z"
    },
    "papermill": {
     "duration": 0.017662,
     "end_time": "2022-08-11T17:18:43.078346",
     "exception": false,
     "start_time": "2022-08-11T17:18:43.060684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c37b47",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:43.089044Z",
     "iopub.status.busy": "2022-08-11T17:18:43.088700Z",
     "iopub.status.idle": "2022-08-11T17:18:43.097374Z",
     "shell.execute_reply": "2022-08-11T17:18:43.096459Z"
    },
    "papermill": {
     "duration": 0.016272,
     "end_time": "2022-08-11T17:18:43.099409",
     "exception": false,
     "start_time": "2022-08-11T17:18:43.083137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a75c3213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:43.109139Z",
     "iopub.status.busy": "2022-08-11T17:18:43.108732Z",
     "iopub.status.idle": "2022-08-11T17:18:48.695428Z",
     "shell.execute_reply": "2022-08-11T17:18:48.694558Z"
    },
    "papermill": {
     "duration": 5.594344,
     "end_time": "2022-08-11T17:18:48.697930",
     "exception": false,
     "start_time": "2022-08-11T17:18:43.103586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_feather('../input/amexfeatureengineering/770_FE_train.feather')\n",
    "target = train.target\n",
    "FEATURES = [col for col in train.columns if col not in ['customer_ID','target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b794f8e",
   "metadata": {
    "papermill": {
     "duration": 0.004518,
     "end_time": "2022-08-11T17:18:48.707077",
     "exception": false,
     "start_time": "2022-08-11T17:18:48.702559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The model\n",
    "\n",
    "Our model has four hidden layers, enriched by a skip connection and a Dropout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18af9b23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:48.716748Z",
     "iopub.status.busy": "2022-08-11T17:18:48.716398Z",
     "iopub.status.idle": "2022-08-11T17:18:48.730684Z",
     "shell.execute_reply": "2022-08-11T17:18:48.729897Z"
    },
    "papermill": {
     "duration": 0.021374,
     "end_time": "2022-08-11T17:18:48.732503",
     "exception": false,
     "start_time": "2022-08-11T17:18:48.711129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class resnetModel(nn.Module):\n",
    "    def __init__(self, num_features,hidden_size,ispretrain=False):\n",
    "        super(resnetModel, self).__init__()\n",
    "        self.ispretrain=ispretrain\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(num_features+hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(num_features+hidden_size, hidden_size))\n",
    "        self.batch_norm20 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout20 = nn.Dropout(0.5)\n",
    "        self.dense20 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "\n",
    "        self.batch_norm3 = nn.BatchNorm1d(2*hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(2*hidden_size, hidden_size))\n",
    "        self.batch_norm30 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout30 = nn.Dropout(0.5)\n",
    "        self.dense30 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "\n",
    "        self.batch_norm4 = nn.BatchNorm1d(2*hidden_size)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        if self.ispretrain:\n",
    "          self.dense4 = nn.utils.weight_norm(nn.Linear(2*hidden_size, 1))\n",
    "        else:\n",
    "          self.dense5 = nn.utils.weight_norm(nn.Linear(2*hidden_size, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.batch_norm1(x)\n",
    "        x1 = F.elu(self.dense1(x1))\n",
    "        x = torch.cat([x,x1],1)\n",
    "        \n",
    "        x2 = self.batch_norm2(x)\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2 = F.elu(self.dense2(x2))\n",
    "        x2 = self.batch_norm20(x2)\n",
    "        x2 = self.dropout20(x2)\n",
    "        x2 = F.elu(self.dense20(x2))\n",
    "        x = torch.cat([x1,x2],1)\n",
    "\n",
    "        x3 = self.batch_norm3(x)\n",
    "        x3 = self.dropout3(x3)\n",
    "        x3 = F.elu(self.dense3(x3))\n",
    "        x3 = self.batch_norm30(x3)\n",
    "        x3 = self.dropout30(x3)\n",
    "        x3 = F.elu(self.dense30(x3))\n",
    "        x3 = torch.cat([x2,x3],1)\n",
    "        \n",
    "        x3 = self.batch_norm4(x3)\n",
    "        x3 = self.dropout4(x3)\n",
    "        if self.ispretrain:\n",
    "          x3 = self.dense4(x3)\n",
    "        else:\n",
    "          x3 = self.dense5(x3)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6941817b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:48.741966Z",
     "iopub.status.busy": "2022-08-11T17:18:48.741660Z",
     "iopub.status.idle": "2022-08-11T17:18:48.867598Z",
     "shell.execute_reply": "2022-08-11T17:18:48.866736Z"
    },
    "papermill": {
     "duration": 0.132957,
     "end_time": "2022-08-11T17:18:48.869736",
     "exception": false,
     "start_time": "2022-08-11T17:18:48.736779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for f,(t_idx,v_idx) in enumerate(skf.split(X=train,y=target)):\n",
    "    train.loc[v_idx,'kfold'] = int(f)\n",
    "\n",
    "train['kfold'] = train['kfold'].astype(int)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a8b5b",
   "metadata": {
    "papermill": {
     "duration": 0.004413,
     "end_time": "2022-08-11T17:18:48.878780",
     "exception": false,
     "start_time": "2022-08-11T17:18:48.874367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed74baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:48.888189Z",
     "iopub.status.busy": "2022-08-11T17:18:48.887829Z",
     "iopub.status.idle": "2022-08-11T17:18:48.897550Z",
     "shell.execute_reply": "2022-08-11T17:18:48.896790Z"
    },
    "papermill": {
     "duration": 0.016627,
     "end_time": "2022-08-11T17:18:48.899499",
     "exception": false,
     "start_time": "2022-08-11T17:18:48.882872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AmexDataset:\n",
    "    def __init__(self,features,target,noise=0.1):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.noise = noise\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        sample = self.features[idx, :].copy()\n",
    "        sample = self.swap_sample(sample)\n",
    "        \n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.target[idx] ,dtype=torch.float)          \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "    def swap_sample(self,sample):\n",
    "            #print(sample.shape)\n",
    "            num_samples = self.features.shape[0]\n",
    "            num_features = self.features.shape[1]\n",
    "            if len(sample.shape) == 2:\n",
    "                batch_size = sample.shape[0]\n",
    "                random_row = np.random.randint(0, num_samples, size=batch_size)\n",
    "                for i in range(batch_size):\n",
    "                    random_col = np.random.rand(num_features) < self.noise\n",
    "                    #print(random_col)\n",
    "                    sample[i, random_col] = self.features[random_row[i], random_col]\n",
    "            else:\n",
    "                batch_size = 1\n",
    "          \n",
    "                random_row = np.random.randint(0, num_samples, size=batch_size)\n",
    "               \n",
    "            \n",
    "                random_col = np.random.rand(num_features) < self.noise\n",
    "                #print(random_col)\n",
    "                #print(random_col)\n",
    "       \n",
    "                sample[ random_col] = self.features[random_row, random_col]\n",
    "                \n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "176fa5df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:48.909720Z",
     "iopub.status.busy": "2022-08-11T17:18:48.909421Z",
     "iopub.status.idle": "2022-08-11T17:18:48.918233Z",
     "shell.execute_reply": "2022-08-11T17:18:48.917401Z"
    },
    "papermill": {
     "duration": 0.015515,
     "end_time": "2022-08-11T17:18:48.919911",
     "exception": false,
     "start_time": "2022-08-11T17:18:48.904396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model,optimizer,scheduler,loss_fn,dataloader,device):\n",
    "    \n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for  data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs,target = data['x'].to(device),data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs[:,0],target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "def valid_fn(model,loss_fn,dataloader,device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = [] \n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs,target = data['x'].to(device),data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs[:,0],target.float())\n",
    "        final_loss +=loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed4dc39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:48.929677Z",
     "iopub.status.busy": "2022-08-11T17:18:48.928957Z",
     "iopub.status.idle": "2022-08-11T17:18:48.939545Z",
     "shell.execute_reply": "2022-08-11T17:18:48.938797Z"
    },
    "papermill": {
     "duration": 0.017205,
     "end_time": "2022-08-11T17:18:48.941276",
     "exception": false,
     "start_time": "2022-08-11T17:18:48.924071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FineTuneScheduler:\n",
    "    def __init__(self, epochs):\n",
    "        self.epochs = epochs\n",
    "        self.epochs_per_step = 0\n",
    "        self.frozen_layers = []\n",
    "\n",
    "    def copy_without_top(self, model, num_features):\n",
    "        self.frozen_layers = []\n",
    "\n",
    "        model_new = resnetModel(num_features,1024)\n",
    "        model_new.load_state_dict(model.state_dict())\n",
    "\n",
    "        # Freeze all weights\n",
    "        for name, param in model_new.named_parameters():\n",
    "            layer_index = name.split('.')[0][-1]\n",
    "\n",
    "            if layer_index == 5:\n",
    "                continue\n",
    "\n",
    "            param.requires_grad = False\n",
    "\n",
    "            # Save frozen layer names\n",
    "            if layer_index not in self.frozen_layers:\n",
    "                self.frozen_layers.append(layer_index)\n",
    "\n",
    "        self.epochs_per_step = self.epochs // len(self.frozen_layers)\n",
    "        \n",
    "        hidden_size = 1024\n",
    "        # Replace the top layers with another ones\n",
    "        model_new.batch_norm4 = nn.BatchNorm1d(2*hidden_size)\n",
    "        model_new.dropout4 = nn.Dropout(0.5)\n",
    "        model_new.dense5 = nn.utils.weight_norm(nn.Linear(2*hidden_size, 1))\n",
    "        model_new.to(DEVICE)\n",
    "        return model_new\n",
    "\n",
    "    def step(self, epoch, model):\n",
    "        if len(self.frozen_layers) == 0:\n",
    "            return\n",
    "\n",
    "        if epoch % self.epochs_per_step == 0:\n",
    "            last_frozen_index = self.frozen_layers[-1]\n",
    "            \n",
    "            # Unfreeze parameters of the last frozen layer\n",
    "            for name, param in model.named_parameters():\n",
    "                layer_index = name.split('.')[0][-1]\n",
    "\n",
    "                if layer_index == last_frozen_index:\n",
    "                    param.requires_grad = True\n",
    "\n",
    "            del self.frozen_layers[-1]  # Remove the last layer as unfrozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d95930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:48.950937Z",
     "iopub.status.busy": "2022-08-11T17:18:48.950296Z",
     "iopub.status.idle": "2022-08-11T17:18:48.954733Z",
     "shell.execute_reply": "2022-08-11T17:18:48.953904Z"
    },
    "papermill": {
     "duration": 0.011323,
     "end_time": "2022-08-11T17:18:48.956684",
     "exception": false,
     "start_time": "2022-08-11T17:18:48.945361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 1e-3\n",
    "NFOLDS = 5           #<-- Update\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0774ffac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:48.965961Z",
     "iopub.status.busy": "2022-08-11T17:18:48.965692Z",
     "iopub.status.idle": "2022-08-11T17:18:48.974301Z",
     "shell.execute_reply": "2022-08-11T17:18:48.973568Z"
    },
    "papermill": {
     "duration": 0.015295,
     "end_time": "2022-08-11T17:18:48.976161",
     "exception": false,
     "start_time": "2022-08-11T17:18:48.960866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "            \n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c73ee38a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:48.985816Z",
     "iopub.status.busy": "2022-08-11T17:18:48.985511Z",
     "iopub.status.idle": "2022-08-11T17:18:48.999360Z",
     "shell.execute_reply": "2022-08-11T17:18:48.998420Z"
    },
    "papermill": {
     "duration": 0.02122,
     "end_time": "2022-08-11T17:18:49.001719",
     "exception": false,
     "start_time": "2022-08-11T17:18:48.980499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold,seed):\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    def train_model(model,fine_tune_scheduler=None):\n",
    "    \n",
    "        x_train,y_train = train_df[FEATURES].values,train_df['target'].values\n",
    "        x_valid,y_valid = valid_df[FEATURES].values,valid_df['target'].values\n",
    "        \n",
    "      #  scaler = StandardScaler()\n",
    "        \n",
    "      #  x_train =  scaler.fit_transform(x_train)\n",
    "      #  x_valid = scaler.transform(x_valid)\n",
    "        \n",
    "        train_dataset = AmexDataset(x_train,y_train)\n",
    "        valid_dataset = AmexDataset(x_valid,y_valid)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss_tr = SmoothBCEwLogits(smoothing=0.001)\n",
    "\n",
    "        oof = np.zeros((len(train),1))\n",
    "        best_loss = np.inf\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            if fine_tune_scheduler is not None:\n",
    "                fine_tune_scheduler.step(epoch, model)\n",
    "\n",
    "            train_loss = train_fn(model, optimizer, scheduler, loss_tr, trainloader, DEVICE)\n",
    "            valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "            print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss:.6f}, valid_loss: {valid_loss:.6f}\")\n",
    "\n",
    "            if np.isnan(valid_loss):\n",
    "                break\n",
    "            \n",
    "            if valid_loss < best_loss:\n",
    "                best_loss = valid_loss\n",
    "                oof[val_idx] = valid_preds\n",
    "                torch.save(model.state_dict(), f\"SEED{seed}_FOLD{fold}_.pth\")\n",
    "       \n",
    "        return oof\n",
    "\n",
    "    fine_tune_scheduler = FineTuneScheduler(EPOCHS)\n",
    "    \n",
    "    pretrained_model = resnetModel(len(FEATURES),1024)\n",
    "    pretrained_model.to(DEVICE)\n",
    "    \n",
    "    print('1st Stage')\n",
    "    \n",
    "    # Train on scored + nonscored targets\n",
    "    train_model(pretrained_model)\n",
    "    \n",
    "    # Load the pretrained model with the best loss\n",
    "    pretrained_model = resnetModel(len(FEATURES),1024)\n",
    "    pretrained_model.load_state_dict(torch.load(f\"SEED{seed}_FOLD{fold}_.pth\"))\n",
    "    pretrained_model.to(DEVICE)\n",
    "                                     \n",
    "    # Copy model without the top layer\n",
    "    final_model = fine_tune_scheduler.copy_without_top(pretrained_model,len(FEATURES))     \n",
    "    \n",
    "    print('2nd Stage / Fine Tuning....')\n",
    "                                     \n",
    "    oof = train_model(final_model,fine_tune_scheduler)       \n",
    "                                    \n",
    "    return oof                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e78a1d32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:49.012959Z",
     "iopub.status.busy": "2022-08-11T17:18:49.012675Z",
     "iopub.status.idle": "2022-08-11T17:18:49.018298Z",
     "shell.execute_reply": "2022-08-11T17:18:49.017552Z"
    },
    "papermill": {
     "duration": 0.012571,
     "end_time": "2022-08-11T17:18:49.020174",
     "exception": false,
     "start_time": "2022-08-11T17:18:49.007603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), 1))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_ = run_training(fold, seed)\n",
    "        oof += oof_\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2692d45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:18:49.029291Z",
     "iopub.status.busy": "2022-08-11T17:18:49.029005Z",
     "iopub.status.idle": "2022-08-11T20:32:10.428079Z",
     "shell.execute_reply": "2022-08-11T20:32:10.426995Z"
    },
    "papermill": {
     "duration": 11601.427828,
     "end_time": "2022-08-11T20:32:10.452111",
     "exception": false,
     "start_time": "2022-08-11T17:18:49.024283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Stage\n",
      "SEED: 41, FOLD: 0, EPOCH: 0, train_loss: 0.295759, valid_loss: 0.233448\n",
      "SEED: 41, FOLD: 0, EPOCH: 1, train_loss: 0.229706, valid_loss: 0.227208\n",
      "SEED: 41, FOLD: 0, EPOCH: 2, train_loss: 0.225234, valid_loss: 0.222241\n",
      "SEED: 41, FOLD: 0, EPOCH: 3, train_loss: 0.222848, valid_loss: 0.225898\n",
      "SEED: 41, FOLD: 0, EPOCH: 4, train_loss: 0.220391, valid_loss: 0.219921\n",
      "SEED: 41, FOLD: 0, EPOCH: 5, train_loss: 0.218838, valid_loss: 0.220065\n",
      "SEED: 41, FOLD: 0, EPOCH: 6, train_loss: 0.216608, valid_loss: 0.220168\n",
      "SEED: 41, FOLD: 0, EPOCH: 7, train_loss: 0.214090, valid_loss: 0.220342\n",
      "SEED: 41, FOLD: 0, EPOCH: 8, train_loss: 0.210673, valid_loss: 0.223702\n",
      "SEED: 41, FOLD: 0, EPOCH: 9, train_loss: 0.206708, valid_loss: 0.224151\n",
      "SEED: 41, FOLD: 0, EPOCH: 10, train_loss: 0.200971, valid_loss: 0.225135\n",
      "SEED: 41, FOLD: 0, EPOCH: 11, train_loss: 0.193660, valid_loss: 0.231898\n",
      "SEED: 41, FOLD: 0, EPOCH: 12, train_loss: 0.185052, valid_loss: 0.237297\n",
      "SEED: 41, FOLD: 0, EPOCH: 13, train_loss: 0.177518, valid_loss: 0.244782\n",
      "SEED: 41, FOLD: 0, EPOCH: 14, train_loss: 0.173142, valid_loss: 0.248844\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 41, FOLD: 0, EPOCH: 0, train_loss: 0.286443, valid_loss: 0.224897\n",
      "SEED: 41, FOLD: 0, EPOCH: 1, train_loss: 0.218355, valid_loss: 0.219854\n",
      "SEED: 41, FOLD: 0, EPOCH: 2, train_loss: 0.217199, valid_loss: 0.219360\n",
      "SEED: 41, FOLD: 0, EPOCH: 3, train_loss: 0.216831, valid_loss: 0.219844\n",
      "SEED: 41, FOLD: 0, EPOCH: 4, train_loss: 0.216310, valid_loss: 0.219905\n",
      "SEED: 41, FOLD: 0, EPOCH: 5, train_loss: 0.215677, valid_loss: 0.218713\n",
      "SEED: 41, FOLD: 0, EPOCH: 6, train_loss: 0.216077, valid_loss: 0.218579\n",
      "SEED: 41, FOLD: 0, EPOCH: 7, train_loss: 0.215382, valid_loss: 0.219902\n",
      "SEED: 41, FOLD: 0, EPOCH: 8, train_loss: 0.215641, valid_loss: 0.218820\n",
      "SEED: 41, FOLD: 0, EPOCH: 9, train_loss: 0.214487, valid_loss: 0.218894\n",
      "SEED: 41, FOLD: 0, EPOCH: 10, train_loss: 0.217777, valid_loss: 0.219452\n",
      "SEED: 41, FOLD: 0, EPOCH: 11, train_loss: 0.213381, valid_loss: 0.219866\n",
      "SEED: 41, FOLD: 0, EPOCH: 12, train_loss: 0.208629, valid_loss: 0.221253\n",
      "SEED: 41, FOLD: 0, EPOCH: 13, train_loss: 0.204586, valid_loss: 0.222198\n",
      "SEED: 41, FOLD: 0, EPOCH: 14, train_loss: 0.202063, valid_loss: 0.223618\n",
      "1st Stage\n",
      "SEED: 41, FOLD: 1, EPOCH: 0, train_loss: 0.295776, valid_loss: 0.239939\n",
      "SEED: 41, FOLD: 1, EPOCH: 1, train_loss: 0.229764, valid_loss: 0.225754\n",
      "SEED: 41, FOLD: 1, EPOCH: 2, train_loss: 0.225143, valid_loss: 0.224446\n",
      "SEED: 41, FOLD: 1, EPOCH: 3, train_loss: 0.222447, valid_loss: 0.228424\n",
      "SEED: 41, FOLD: 1, EPOCH: 4, train_loss: 0.220283, valid_loss: 0.223889\n",
      "SEED: 41, FOLD: 1, EPOCH: 5, train_loss: 0.218567, valid_loss: 0.224433\n",
      "SEED: 41, FOLD: 1, EPOCH: 6, train_loss: 0.216438, valid_loss: 0.222608\n",
      "SEED: 41, FOLD: 1, EPOCH: 7, train_loss: 0.213730, valid_loss: 0.222873\n",
      "SEED: 41, FOLD: 1, EPOCH: 8, train_loss: 0.210639, valid_loss: 0.225239\n",
      "SEED: 41, FOLD: 1, EPOCH: 9, train_loss: 0.206197, valid_loss: 0.226756\n",
      "SEED: 41, FOLD: 1, EPOCH: 10, train_loss: 0.200563, valid_loss: 0.226828\n",
      "SEED: 41, FOLD: 1, EPOCH: 11, train_loss: 0.193731, valid_loss: 0.233298\n",
      "SEED: 41, FOLD: 1, EPOCH: 12, train_loss: 0.185367, valid_loss: 0.240682\n",
      "SEED: 41, FOLD: 1, EPOCH: 13, train_loss: 0.177605, valid_loss: 0.243887\n",
      "SEED: 41, FOLD: 1, EPOCH: 14, train_loss: 0.173470, valid_loss: 0.249436\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 41, FOLD: 1, EPOCH: 0, train_loss: 0.287315, valid_loss: 0.224152\n",
      "SEED: 41, FOLD: 1, EPOCH: 1, train_loss: 0.213594, valid_loss: 0.222567\n",
      "SEED: 41, FOLD: 1, EPOCH: 2, train_loss: 0.212688, valid_loss: 0.222476\n",
      "SEED: 41, FOLD: 1, EPOCH: 3, train_loss: 0.211850, valid_loss: 0.222693\n",
      "SEED: 41, FOLD: 1, EPOCH: 4, train_loss: 0.211224, valid_loss: 0.222754\n",
      "SEED: 41, FOLD: 1, EPOCH: 5, train_loss: 0.210154, valid_loss: 0.222190\n",
      "SEED: 41, FOLD: 1, EPOCH: 6, train_loss: 0.210818, valid_loss: 0.221698\n",
      "SEED: 41, FOLD: 1, EPOCH: 7, train_loss: 0.209435, valid_loss: 0.224345\n",
      "SEED: 41, FOLD: 1, EPOCH: 8, train_loss: 0.209918, valid_loss: 0.223084\n",
      "SEED: 41, FOLD: 1, EPOCH: 9, train_loss: 0.208202, valid_loss: 0.222119\n",
      "SEED: 41, FOLD: 1, EPOCH: 10, train_loss: 0.212350, valid_loss: 0.224022\n",
      "SEED: 41, FOLD: 1, EPOCH: 11, train_loss: 0.206117, valid_loss: 0.226997\n",
      "SEED: 41, FOLD: 1, EPOCH: 12, train_loss: 0.200366, valid_loss: 0.231040\n",
      "SEED: 41, FOLD: 1, EPOCH: 13, train_loss: 0.195248, valid_loss: 0.231800\n",
      "SEED: 41, FOLD: 1, EPOCH: 14, train_loss: 0.191961, valid_loss: 0.237354\n",
      "1st Stage\n",
      "SEED: 41, FOLD: 2, EPOCH: 0, train_loss: 0.295791, valid_loss: 0.230668\n",
      "SEED: 41, FOLD: 2, EPOCH: 1, train_loss: 0.230248, valid_loss: 0.221797\n",
      "SEED: 41, FOLD: 2, EPOCH: 2, train_loss: 0.225520, valid_loss: 0.221405\n",
      "SEED: 41, FOLD: 2, EPOCH: 3, train_loss: 0.222961, valid_loss: 0.220273\n",
      "SEED: 41, FOLD: 2, EPOCH: 4, train_loss: 0.220704, valid_loss: 0.221693\n",
      "SEED: 41, FOLD: 2, EPOCH: 5, train_loss: 0.218774, valid_loss: 0.220276\n",
      "SEED: 41, FOLD: 2, EPOCH: 6, train_loss: 0.216455, valid_loss: 0.220696\n",
      "SEED: 41, FOLD: 2, EPOCH: 7, train_loss: 0.214038, valid_loss: 0.220167\n",
      "SEED: 41, FOLD: 2, EPOCH: 8, train_loss: 0.210559, valid_loss: 0.222637\n",
      "SEED: 41, FOLD: 2, EPOCH: 9, train_loss: 0.206126, valid_loss: 0.226134\n",
      "SEED: 41, FOLD: 2, EPOCH: 10, train_loss: 0.200186, valid_loss: 0.226646\n",
      "SEED: 41, FOLD: 2, EPOCH: 11, train_loss: 0.192554, valid_loss: 0.231596\n",
      "SEED: 41, FOLD: 2, EPOCH: 12, train_loss: 0.183997, valid_loss: 0.239741\n",
      "SEED: 41, FOLD: 2, EPOCH: 13, train_loss: 0.176076, valid_loss: 0.247686\n",
      "SEED: 41, FOLD: 2, EPOCH: 14, train_loss: 0.171993, valid_loss: 0.248829\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 41, FOLD: 2, EPOCH: 0, train_loss: 0.275476, valid_loss: 0.220924\n",
      "SEED: 41, FOLD: 2, EPOCH: 1, train_loss: 0.209994, valid_loss: 0.219517\n",
      "SEED: 41, FOLD: 2, EPOCH: 2, train_loss: 0.208522, valid_loss: 0.222173\n",
      "SEED: 41, FOLD: 2, EPOCH: 3, train_loss: 0.208112, valid_loss: 0.220276\n",
      "SEED: 41, FOLD: 2, EPOCH: 4, train_loss: 0.208167, valid_loss: 0.220802\n",
      "SEED: 41, FOLD: 2, EPOCH: 5, train_loss: 0.206624, valid_loss: 0.222289\n",
      "SEED: 41, FOLD: 2, EPOCH: 6, train_loss: 0.207194, valid_loss: 0.220381\n",
      "SEED: 41, FOLD: 2, EPOCH: 7, train_loss: 0.205704, valid_loss: 0.221568\n",
      "SEED: 41, FOLD: 2, EPOCH: 8, train_loss: 0.205920, valid_loss: 0.221584\n",
      "SEED: 41, FOLD: 2, EPOCH: 9, train_loss: 0.204413, valid_loss: 0.222242\n",
      "SEED: 41, FOLD: 2, EPOCH: 10, train_loss: 0.209203, valid_loss: 0.221903\n",
      "SEED: 41, FOLD: 2, EPOCH: 11, train_loss: 0.202203, valid_loss: 0.225261\n",
      "SEED: 41, FOLD: 2, EPOCH: 12, train_loss: 0.194624, valid_loss: 0.229963\n",
      "SEED: 41, FOLD: 2, EPOCH: 13, train_loss: 0.188205, valid_loss: 0.234678\n",
      "SEED: 41, FOLD: 2, EPOCH: 14, train_loss: 0.185025, valid_loss: 0.238931\n",
      "1st Stage\n",
      "SEED: 41, FOLD: 3, EPOCH: 0, train_loss: 0.296315, valid_loss: 0.235607\n",
      "SEED: 41, FOLD: 3, EPOCH: 1, train_loss: 0.229793, valid_loss: 0.223700\n",
      "SEED: 41, FOLD: 3, EPOCH: 2, train_loss: 0.224927, valid_loss: 0.222712\n",
      "SEED: 41, FOLD: 3, EPOCH: 3, train_loss: 0.222195, valid_loss: 0.223175\n",
      "SEED: 41, FOLD: 3, EPOCH: 4, train_loss: 0.220244, valid_loss: 0.220817\n",
      "SEED: 41, FOLD: 3, EPOCH: 5, train_loss: 0.218343, valid_loss: 0.223432\n",
      "SEED: 41, FOLD: 3, EPOCH: 6, train_loss: 0.215847, valid_loss: 0.220812\n",
      "SEED: 41, FOLD: 3, EPOCH: 7, train_loss: 0.213291, valid_loss: 0.222961\n",
      "SEED: 41, FOLD: 3, EPOCH: 8, train_loss: 0.210116, valid_loss: 0.225592\n",
      "SEED: 41, FOLD: 3, EPOCH: 9, train_loss: 0.205817, valid_loss: 0.228188\n",
      "SEED: 41, FOLD: 3, EPOCH: 10, train_loss: 0.199684, valid_loss: 0.229692\n",
      "SEED: 41, FOLD: 3, EPOCH: 11, train_loss: 0.192239, valid_loss: 0.234384\n",
      "SEED: 41, FOLD: 3, EPOCH: 12, train_loss: 0.183376, valid_loss: 0.243810\n",
      "SEED: 41, FOLD: 3, EPOCH: 13, train_loss: 0.175621, valid_loss: 0.251834\n",
      "SEED: 41, FOLD: 3, EPOCH: 14, train_loss: 0.171894, valid_loss: 0.256718\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 41, FOLD: 3, EPOCH: 0, train_loss: 0.275472, valid_loss: 0.225163\n",
      "SEED: 41, FOLD: 3, EPOCH: 1, train_loss: 0.213015, valid_loss: 0.220993\n",
      "SEED: 41, FOLD: 3, EPOCH: 2, train_loss: 0.211158, valid_loss: 0.220713\n",
      "SEED: 41, FOLD: 3, EPOCH: 3, train_loss: 0.210801, valid_loss: 0.221004\n",
      "SEED: 41, FOLD: 3, EPOCH: 4, train_loss: 0.210960, valid_loss: 0.220913\n",
      "SEED: 41, FOLD: 3, EPOCH: 5, train_loss: 0.209746, valid_loss: 0.221055\n",
      "SEED: 41, FOLD: 3, EPOCH: 6, train_loss: 0.209714, valid_loss: 0.223636\n",
      "SEED: 41, FOLD: 3, EPOCH: 7, train_loss: 0.208846, valid_loss: 0.222953\n",
      "SEED: 41, FOLD: 3, EPOCH: 8, train_loss: 0.209252, valid_loss: 0.221653\n",
      "SEED: 41, FOLD: 3, EPOCH: 9, train_loss: 0.207793, valid_loss: 0.223995\n",
      "SEED: 41, FOLD: 3, EPOCH: 10, train_loss: 0.212163, valid_loss: 0.224387\n",
      "SEED: 41, FOLD: 3, EPOCH: 11, train_loss: 0.205985, valid_loss: 0.225028\n",
      "SEED: 41, FOLD: 3, EPOCH: 12, train_loss: 0.199300, valid_loss: 0.228622\n",
      "SEED: 41, FOLD: 3, EPOCH: 13, train_loss: 0.193463, valid_loss: 0.233180\n",
      "SEED: 41, FOLD: 3, EPOCH: 14, train_loss: 0.190857, valid_loss: 0.242793\n",
      "1st Stage\n",
      "SEED: 41, FOLD: 4, EPOCH: 0, train_loss: 0.296662, valid_loss: 0.232259\n",
      "SEED: 41, FOLD: 4, EPOCH: 1, train_loss: 0.230537, valid_loss: 0.223355\n",
      "SEED: 41, FOLD: 4, EPOCH: 2, train_loss: 0.225134, valid_loss: 0.220339\n",
      "SEED: 41, FOLD: 4, EPOCH: 3, train_loss: 0.222952, valid_loss: 0.219101\n",
      "SEED: 41, FOLD: 4, EPOCH: 4, train_loss: 0.220980, valid_loss: 0.220126\n",
      "SEED: 41, FOLD: 4, EPOCH: 5, train_loss: 0.219045, valid_loss: 0.219656\n",
      "SEED: 41, FOLD: 4, EPOCH: 6, train_loss: 0.216765, valid_loss: 0.218078\n",
      "SEED: 41, FOLD: 4, EPOCH: 7, train_loss: 0.214194, valid_loss: 0.219342\n",
      "SEED: 41, FOLD: 4, EPOCH: 8, train_loss: 0.210834, valid_loss: 0.224143\n",
      "SEED: 41, FOLD: 4, EPOCH: 9, train_loss: 0.206283, valid_loss: 0.222497\n",
      "SEED: 41, FOLD: 4, EPOCH: 10, train_loss: 0.200307, valid_loss: 0.226732\n",
      "SEED: 41, FOLD: 4, EPOCH: 11, train_loss: 0.192365, valid_loss: 0.231818\n",
      "SEED: 41, FOLD: 4, EPOCH: 12, train_loss: 0.183790, valid_loss: 0.238730\n",
      "SEED: 41, FOLD: 4, EPOCH: 13, train_loss: 0.176473, valid_loss: 0.246493\n",
      "SEED: 41, FOLD: 4, EPOCH: 14, train_loss: 0.172094, valid_loss: 0.245614\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 41, FOLD: 4, EPOCH: 0, train_loss: 0.278592, valid_loss: 0.221383\n",
      "SEED: 41, FOLD: 4, EPOCH: 1, train_loss: 0.213614, valid_loss: 0.219811\n",
      "SEED: 41, FOLD: 4, EPOCH: 2, train_loss: 0.211909, valid_loss: 0.217771\n",
      "SEED: 41, FOLD: 4, EPOCH: 3, train_loss: 0.211682, valid_loss: 0.219029\n",
      "SEED: 41, FOLD: 4, EPOCH: 4, train_loss: 0.211576, valid_loss: 0.217193\n",
      "SEED: 41, FOLD: 4, EPOCH: 5, train_loss: 0.210380, valid_loss: 0.217956\n",
      "SEED: 41, FOLD: 4, EPOCH: 6, train_loss: 0.210504, valid_loss: 0.219703\n",
      "SEED: 41, FOLD: 4, EPOCH: 7, train_loss: 0.209529, valid_loss: 0.219472\n",
      "SEED: 41, FOLD: 4, EPOCH: 8, train_loss: 0.210064, valid_loss: 0.218498\n",
      "SEED: 41, FOLD: 4, EPOCH: 9, train_loss: 0.208634, valid_loss: 0.219188\n",
      "SEED: 41, FOLD: 4, EPOCH: 10, train_loss: 0.212984, valid_loss: 0.219541\n",
      "SEED: 41, FOLD: 4, EPOCH: 11, train_loss: 0.206606, valid_loss: 0.223727\n",
      "SEED: 41, FOLD: 4, EPOCH: 12, train_loss: 0.200053, valid_loss: 0.227025\n",
      "SEED: 41, FOLD: 4, EPOCH: 13, train_loss: 0.194176, valid_loss: 0.230472\n",
      "SEED: 41, FOLD: 4, EPOCH: 14, train_loss: 0.191218, valid_loss: 0.234695\n",
      "1st Stage\n",
      "SEED: 42, FOLD: 0, EPOCH: 0, train_loss: 0.294854, valid_loss: 0.227808\n",
      "SEED: 42, FOLD: 0, EPOCH: 1, train_loss: 0.229666, valid_loss: 0.224571\n",
      "SEED: 42, FOLD: 0, EPOCH: 2, train_loss: 0.225138, valid_loss: 0.222084\n",
      "SEED: 42, FOLD: 0, EPOCH: 3, train_loss: 0.222167, valid_loss: 0.221501\n",
      "SEED: 42, FOLD: 0, EPOCH: 4, train_loss: 0.220878, valid_loss: 0.220628\n",
      "SEED: 42, FOLD: 0, EPOCH: 5, train_loss: 0.218775, valid_loss: 0.219945\n",
      "SEED: 42, FOLD: 0, EPOCH: 6, train_loss: 0.216544, valid_loss: 0.219509\n",
      "SEED: 42, FOLD: 0, EPOCH: 7, train_loss: 0.214111, valid_loss: 0.220673\n",
      "SEED: 42, FOLD: 0, EPOCH: 8, train_loss: 0.210870, valid_loss: 0.223577\n",
      "SEED: 42, FOLD: 0, EPOCH: 9, train_loss: 0.207239, valid_loss: 0.224719\n",
      "SEED: 42, FOLD: 0, EPOCH: 10, train_loss: 0.201105, valid_loss: 0.227077\n",
      "SEED: 42, FOLD: 0, EPOCH: 11, train_loss: 0.193680, valid_loss: 0.233512\n",
      "SEED: 42, FOLD: 0, EPOCH: 12, train_loss: 0.184671, valid_loss: 0.240170\n",
      "SEED: 42, FOLD: 0, EPOCH: 13, train_loss: 0.177839, valid_loss: 0.244118\n",
      "SEED: 42, FOLD: 0, EPOCH: 14, train_loss: 0.173006, valid_loss: 0.248745\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 42, FOLD: 0, EPOCH: 0, train_loss: 0.269633, valid_loss: 0.220665\n",
      "SEED: 42, FOLD: 0, EPOCH: 1, train_loss: 0.213610, valid_loss: 0.223897\n",
      "SEED: 42, FOLD: 0, EPOCH: 2, train_loss: 0.212518, valid_loss: 0.219419\n",
      "SEED: 42, FOLD: 0, EPOCH: 3, train_loss: 0.212022, valid_loss: 0.219438\n",
      "SEED: 42, FOLD: 0, EPOCH: 4, train_loss: 0.211783, valid_loss: 0.219299\n",
      "SEED: 42, FOLD: 0, EPOCH: 5, train_loss: 0.210546, valid_loss: 0.219819\n",
      "SEED: 42, FOLD: 0, EPOCH: 6, train_loss: 0.210773, valid_loss: 0.221796\n",
      "SEED: 42, FOLD: 0, EPOCH: 7, train_loss: 0.210133, valid_loss: 0.219622\n",
      "SEED: 42, FOLD: 0, EPOCH: 8, train_loss: 0.210255, valid_loss: 0.219417\n",
      "SEED: 42, FOLD: 0, EPOCH: 9, train_loss: 0.209104, valid_loss: 0.219614\n",
      "SEED: 42, FOLD: 0, EPOCH: 10, train_loss: 0.213546, valid_loss: 0.219738\n",
      "SEED: 42, FOLD: 0, EPOCH: 11, train_loss: 0.206985, valid_loss: 0.221373\n",
      "SEED: 42, FOLD: 0, EPOCH: 12, train_loss: 0.200794, valid_loss: 0.223879\n",
      "SEED: 42, FOLD: 0, EPOCH: 13, train_loss: 0.195659, valid_loss: 0.227260\n",
      "SEED: 42, FOLD: 0, EPOCH: 14, train_loss: 0.192794, valid_loss: 0.227941\n",
      "1st Stage\n",
      "SEED: 42, FOLD: 1, EPOCH: 0, train_loss: 0.294013, valid_loss: 0.230097\n",
      "SEED: 42, FOLD: 1, EPOCH: 1, train_loss: 0.229532, valid_loss: 0.225869\n",
      "SEED: 42, FOLD: 1, EPOCH: 2, train_loss: 0.224656, valid_loss: 0.226072\n",
      "SEED: 42, FOLD: 1, EPOCH: 3, train_loss: 0.221997, valid_loss: 0.222381\n",
      "SEED: 42, FOLD: 1, EPOCH: 4, train_loss: 0.220568, valid_loss: 0.222130\n",
      "SEED: 42, FOLD: 1, EPOCH: 5, train_loss: 0.218686, valid_loss: 0.220900\n",
      "SEED: 42, FOLD: 1, EPOCH: 6, train_loss: 0.216525, valid_loss: 0.221376\n",
      "SEED: 42, FOLD: 1, EPOCH: 7, train_loss: 0.213653, valid_loss: 0.221879\n",
      "SEED: 42, FOLD: 1, EPOCH: 8, train_loss: 0.210651, valid_loss: 0.222594\n",
      "SEED: 42, FOLD: 1, EPOCH: 9, train_loss: 0.206434, valid_loss: 0.229165\n",
      "SEED: 42, FOLD: 1, EPOCH: 10, train_loss: 0.200760, valid_loss: 0.229389\n",
      "SEED: 42, FOLD: 1, EPOCH: 11, train_loss: 0.193243, valid_loss: 0.233252\n",
      "SEED: 42, FOLD: 1, EPOCH: 12, train_loss: 0.184472, valid_loss: 0.240524\n",
      "SEED: 42, FOLD: 1, EPOCH: 13, train_loss: 0.176776, valid_loss: 0.246258\n",
      "SEED: 42, FOLD: 1, EPOCH: 14, train_loss: 0.172711, valid_loss: 0.248142\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 42, FOLD: 1, EPOCH: 0, train_loss: 0.264421, valid_loss: 0.226356\n",
      "SEED: 42, FOLD: 1, EPOCH: 1, train_loss: 0.215196, valid_loss: 0.225726\n",
      "SEED: 42, FOLD: 1, EPOCH: 2, train_loss: 0.214322, valid_loss: 0.221731\n",
      "SEED: 42, FOLD: 1, EPOCH: 3, train_loss: 0.213836, valid_loss: 0.221595\n",
      "SEED: 42, FOLD: 1, EPOCH: 4, train_loss: 0.213817, valid_loss: 0.220441\n",
      "SEED: 42, FOLD: 1, EPOCH: 5, train_loss: 0.212511, valid_loss: 0.221126\n",
      "SEED: 42, FOLD: 1, EPOCH: 6, train_loss: 0.213097, valid_loss: 0.221388\n",
      "SEED: 42, FOLD: 1, EPOCH: 7, train_loss: 0.212161, valid_loss: 0.220593\n",
      "SEED: 42, FOLD: 1, EPOCH: 8, train_loss: 0.212490, valid_loss: 0.220218\n",
      "SEED: 42, FOLD: 1, EPOCH: 9, train_loss: 0.211267, valid_loss: 0.220743\n",
      "SEED: 42, FOLD: 1, EPOCH: 10, train_loss: 0.215063, valid_loss: 0.221565\n",
      "SEED: 42, FOLD: 1, EPOCH: 11, train_loss: 0.209945, valid_loss: 0.222671\n",
      "SEED: 42, FOLD: 1, EPOCH: 12, train_loss: 0.204792, valid_loss: 0.226154\n",
      "SEED: 42, FOLD: 1, EPOCH: 13, train_loss: 0.200130, valid_loss: 0.226776\n",
      "SEED: 42, FOLD: 1, EPOCH: 14, train_loss: 0.197224, valid_loss: 0.228181\n",
      "1st Stage\n",
      "SEED: 42, FOLD: 2, EPOCH: 0, train_loss: 0.294674, valid_loss: 0.226966\n",
      "SEED: 42, FOLD: 2, EPOCH: 1, train_loss: 0.229935, valid_loss: 0.222482\n",
      "SEED: 42, FOLD: 2, EPOCH: 2, train_loss: 0.225450, valid_loss: 0.221234\n",
      "SEED: 42, FOLD: 2, EPOCH: 3, train_loss: 0.222600, valid_loss: 0.220844\n",
      "SEED: 42, FOLD: 2, EPOCH: 4, train_loss: 0.220753, valid_loss: 0.220237\n",
      "SEED: 42, FOLD: 2, EPOCH: 5, train_loss: 0.219008, valid_loss: 0.218744\n",
      "SEED: 42, FOLD: 2, EPOCH: 6, train_loss: 0.216418, valid_loss: 0.218609\n",
      "SEED: 42, FOLD: 2, EPOCH: 7, train_loss: 0.213639, valid_loss: 0.220161\n",
      "SEED: 42, FOLD: 2, EPOCH: 8, train_loss: 0.210818, valid_loss: 0.220069\n",
      "SEED: 42, FOLD: 2, EPOCH: 9, train_loss: 0.206017, valid_loss: 0.223599\n",
      "SEED: 42, FOLD: 2, EPOCH: 10, train_loss: 0.200327, valid_loss: 0.226376\n",
      "SEED: 42, FOLD: 2, EPOCH: 11, train_loss: 0.192985, valid_loss: 0.231907\n",
      "SEED: 42, FOLD: 2, EPOCH: 12, train_loss: 0.183785, valid_loss: 0.238257\n",
      "SEED: 42, FOLD: 2, EPOCH: 13, train_loss: 0.175934, valid_loss: 0.247292\n",
      "SEED: 42, FOLD: 2, EPOCH: 14, train_loss: 0.171775, valid_loss: 0.250452\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 42, FOLD: 2, EPOCH: 0, train_loss: 0.267717, valid_loss: 0.221355\n",
      "SEED: 42, FOLD: 2, EPOCH: 1, train_loss: 0.213055, valid_loss: 0.220631\n",
      "SEED: 42, FOLD: 2, EPOCH: 2, train_loss: 0.211803, valid_loss: 0.219963\n",
      "SEED: 42, FOLD: 2, EPOCH: 3, train_loss: 0.211984, valid_loss: 0.218671\n",
      "SEED: 42, FOLD: 2, EPOCH: 4, train_loss: 0.211231, valid_loss: 0.218148\n",
      "SEED: 42, FOLD: 2, EPOCH: 5, train_loss: 0.210062, valid_loss: 0.219615\n",
      "SEED: 42, FOLD: 2, EPOCH: 6, train_loss: 0.210687, valid_loss: 0.219438\n",
      "SEED: 42, FOLD: 2, EPOCH: 7, train_loss: 0.209555, valid_loss: 0.219491\n",
      "SEED: 42, FOLD: 2, EPOCH: 8, train_loss: 0.209591, valid_loss: 0.219249\n",
      "SEED: 42, FOLD: 2, EPOCH: 9, train_loss: 0.208438, valid_loss: 0.218919\n",
      "SEED: 42, FOLD: 2, EPOCH: 10, train_loss: 0.212499, valid_loss: 0.219962\n",
      "SEED: 42, FOLD: 2, EPOCH: 11, train_loss: 0.206174, valid_loss: 0.221416\n",
      "SEED: 42, FOLD: 2, EPOCH: 12, train_loss: 0.200009, valid_loss: 0.226507\n",
      "SEED: 42, FOLD: 2, EPOCH: 13, train_loss: 0.194047, valid_loss: 0.232085\n",
      "SEED: 42, FOLD: 2, EPOCH: 14, train_loss: 0.191321, valid_loss: 0.238683\n",
      "1st Stage\n",
      "SEED: 42, FOLD: 3, EPOCH: 0, train_loss: 0.295951, valid_loss: 0.230658\n",
      "SEED: 42, FOLD: 3, EPOCH: 1, train_loss: 0.230302, valid_loss: 0.224658\n",
      "SEED: 42, FOLD: 3, EPOCH: 2, train_loss: 0.225257, valid_loss: 0.233321\n",
      "SEED: 42, FOLD: 3, EPOCH: 3, train_loss: 0.222554, valid_loss: 0.220689\n",
      "SEED: 42, FOLD: 3, EPOCH: 4, train_loss: 0.220655, valid_loss: 0.222096\n",
      "SEED: 42, FOLD: 3, EPOCH: 5, train_loss: 0.218390, valid_loss: 0.220986\n",
      "SEED: 42, FOLD: 3, EPOCH: 6, train_loss: 0.216238, valid_loss: 0.223441\n",
      "SEED: 42, FOLD: 3, EPOCH: 7, train_loss: 0.213589, valid_loss: 0.223504\n",
      "SEED: 42, FOLD: 3, EPOCH: 8, train_loss: 0.210785, valid_loss: 0.223384\n",
      "SEED: 42, FOLD: 3, EPOCH: 9, train_loss: 0.206227, valid_loss: 0.224607\n",
      "SEED: 42, FOLD: 3, EPOCH: 10, train_loss: 0.200330, valid_loss: 0.229072\n",
      "SEED: 42, FOLD: 3, EPOCH: 11, train_loss: 0.193181, valid_loss: 0.234735\n",
      "SEED: 42, FOLD: 3, EPOCH: 12, train_loss: 0.184656, valid_loss: 0.242586\n",
      "SEED: 42, FOLD: 3, EPOCH: 13, train_loss: 0.176655, valid_loss: 0.250867\n",
      "SEED: 42, FOLD: 3, EPOCH: 14, train_loss: 0.173068, valid_loss: 0.253220\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 42, FOLD: 3, EPOCH: 0, train_loss: 0.260314, valid_loss: 0.224162\n",
      "SEED: 42, FOLD: 3, EPOCH: 1, train_loss: 0.220582, valid_loss: 0.221632\n",
      "SEED: 42, FOLD: 3, EPOCH: 2, train_loss: 0.218843, valid_loss: 0.221382\n",
      "SEED: 42, FOLD: 3, EPOCH: 3, train_loss: 0.218536, valid_loss: 0.221592\n",
      "SEED: 42, FOLD: 3, EPOCH: 4, train_loss: 0.218357, valid_loss: 0.221351\n",
      "SEED: 42, FOLD: 3, EPOCH: 5, train_loss: 0.217709, valid_loss: 0.221007\n",
      "SEED: 42, FOLD: 3, EPOCH: 6, train_loss: 0.218116, valid_loss: 0.222862\n",
      "SEED: 42, FOLD: 3, EPOCH: 7, train_loss: 0.217390, valid_loss: 0.219631\n",
      "SEED: 42, FOLD: 3, EPOCH: 8, train_loss: 0.217396, valid_loss: 0.220283\n",
      "SEED: 42, FOLD: 3, EPOCH: 9, train_loss: 0.216484, valid_loss: 0.219135\n",
      "SEED: 42, FOLD: 3, EPOCH: 10, train_loss: 0.219990, valid_loss: 0.220674\n",
      "SEED: 42, FOLD: 3, EPOCH: 11, train_loss: 0.215626, valid_loss: 0.221107\n",
      "SEED: 42, FOLD: 3, EPOCH: 12, train_loss: 0.211625, valid_loss: 0.221439\n",
      "SEED: 42, FOLD: 3, EPOCH: 13, train_loss: 0.208027, valid_loss: 0.223739\n",
      "SEED: 42, FOLD: 3, EPOCH: 14, train_loss: 0.205879, valid_loss: 0.222544\n",
      "1st Stage\n",
      "SEED: 42, FOLD: 4, EPOCH: 0, train_loss: 0.295741, valid_loss: 0.228897\n",
      "SEED: 42, FOLD: 4, EPOCH: 1, train_loss: 0.230914, valid_loss: 0.225222\n",
      "SEED: 42, FOLD: 4, EPOCH: 2, train_loss: 0.225730, valid_loss: 0.226000\n",
      "SEED: 42, FOLD: 4, EPOCH: 3, train_loss: 0.223040, valid_loss: 0.219156\n",
      "SEED: 42, FOLD: 4, EPOCH: 4, train_loss: 0.221149, valid_loss: 0.218302\n",
      "SEED: 42, FOLD: 4, EPOCH: 5, train_loss: 0.219038, valid_loss: 0.218279\n",
      "SEED: 42, FOLD: 4, EPOCH: 6, train_loss: 0.217014, valid_loss: 0.219148\n",
      "SEED: 42, FOLD: 4, EPOCH: 7, train_loss: 0.214332, valid_loss: 0.218459\n",
      "SEED: 42, FOLD: 4, EPOCH: 8, train_loss: 0.211171, valid_loss: 0.220489\n",
      "SEED: 42, FOLD: 4, EPOCH: 9, train_loss: 0.206939, valid_loss: 0.225088\n",
      "SEED: 42, FOLD: 4, EPOCH: 10, train_loss: 0.200829, valid_loss: 0.230573\n",
      "SEED: 42, FOLD: 4, EPOCH: 11, train_loss: 0.192936, valid_loss: 0.229779\n",
      "SEED: 42, FOLD: 4, EPOCH: 12, train_loss: 0.185428, valid_loss: 0.234648\n",
      "SEED: 42, FOLD: 4, EPOCH: 13, train_loss: 0.177603, valid_loss: 0.246842\n",
      "SEED: 42, FOLD: 4, EPOCH: 14, train_loss: 0.173134, valid_loss: 0.248837\n",
      "2nd Stage / Fine Tuning....\n",
      "SEED: 42, FOLD: 4, EPOCH: 0, train_loss: 0.268649, valid_loss: 0.221013\n",
      "SEED: 42, FOLD: 4, EPOCH: 1, train_loss: 0.216787, valid_loss: 0.218420\n",
      "SEED: 42, FOLD: 4, EPOCH: 2, train_loss: 0.215298, valid_loss: 0.218861\n",
      "SEED: 42, FOLD: 4, EPOCH: 3, train_loss: 0.215256, valid_loss: 0.217986\n",
      "SEED: 42, FOLD: 4, EPOCH: 4, train_loss: 0.214664, valid_loss: 0.218090\n",
      "SEED: 42, FOLD: 4, EPOCH: 5, train_loss: 0.213822, valid_loss: 0.218199\n",
      "SEED: 42, FOLD: 4, EPOCH: 6, train_loss: 0.214109, valid_loss: 0.218288\n",
      "SEED: 42, FOLD: 4, EPOCH: 7, train_loss: 0.212994, valid_loss: 0.217462\n",
      "SEED: 42, FOLD: 4, EPOCH: 8, train_loss: 0.213077, valid_loss: 0.217193\n",
      "SEED: 42, FOLD: 4, EPOCH: 9, train_loss: 0.212218, valid_loss: 0.217278\n",
      "SEED: 42, FOLD: 4, EPOCH: 10, train_loss: 0.216099, valid_loss: 0.217152\n",
      "SEED: 42, FOLD: 4, EPOCH: 11, train_loss: 0.210319, valid_loss: 0.220862\n",
      "SEED: 42, FOLD: 4, EPOCH: 12, train_loss: 0.204703, valid_loss: 0.222714\n",
      "SEED: 42, FOLD: 4, EPOCH: 13, train_loss: 0.199836, valid_loss: 0.226601\n",
      "SEED: 42, FOLD: 4, EPOCH: 14, train_loss: 0.197113, valid_loss: 0.226208\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [41,42]  #<-- Update\n",
    "oof = np.zeros((len(train),1))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78ff1eed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:32:10.493755Z",
     "iopub.status.busy": "2022-08-11T20:32:10.493113Z",
     "iopub.status.idle": "2022-08-11T20:32:10.675789Z",
     "shell.execute_reply": "2022-08-11T20:32:10.674900Z"
    },
    "papermill": {
     "duration": 0.205791,
     "end_time": "2022-08-11T20:32:10.678023",
     "exception": false,
     "start_time": "2022-08-11T20:32:10.472232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_ap = amex_metric_mod(target,oof[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b02e411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:32:10.720168Z",
     "iopub.status.busy": "2022-08-11T20:32:10.719376Z",
     "iopub.status.idle": "2022-08-11T20:32:10.726522Z",
     "shell.execute_reply": "2022-08-11T20:32:10.725765Z"
    },
    "papermill": {
     "duration": 0.030535,
     "end_time": "2022-08-11T20:32:10.728733",
     "exception": false,
     "start_time": "2022-08-11T20:32:10.698198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918790490212578"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c5fe01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:32:10.770693Z",
     "iopub.status.busy": "2022-08-11T20:32:10.769919Z",
     "iopub.status.idle": "2022-08-11T20:32:11.949743Z",
     "shell.execute_reply": "2022-08-11T20:32:11.948598Z"
    },
    "papermill": {
     "duration": 1.204756,
     "end_time": "2022-08-11T20:32:11.953595",
     "exception": false,
     "start_time": "2022-08-11T20:32:10.748839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof = pd.DataFrame({'customer_ID':train.customer_ID,'target':train.target,'oof_pred':oof[:,0]})\n",
    "oof.to_csv('oof_transfer_learning.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11622.356622,
   "end_time": "2022-08-11T20:32:14.330320",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-11T17:18:31.973698",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
